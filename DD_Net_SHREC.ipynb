{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn6uaZYCINDy"
      },
      "source": [
        "! pip install -q keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBLSQB8bRtdT"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import scipy.ndimage.interpolation as inter\n",
        "from scipy.signal import medfilt \n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "from keras.optimizers import *\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.layers.core import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from keras.layers.convolutional import *\n",
        "from keras import backend as K\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import google.colab.files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4Dd8w2Uaks3"
      },
      "source": [
        "1. Define configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyxDYnOJaotB"
      },
      "source": [
        "random.seed(1234)\n",
        "\n",
        "class Config():\n",
        "    def __init__(self):\n",
        "        self.frame_l = 32 # the length of frames\n",
        "        self.joint_n = 12 # the number of joints\n",
        "        self.joint_n = 22 # the number of joints\n",
        "        self.joint_d = 3 # the dimension of joints\n",
        "        self.clc_coarse = 14 # the number of coarse class\n",
        "        self.clc_fine = 28 # the number of fine-grained class\n",
        "        self.feat_d = 231\n",
        "        self.filters = 64\n",
        "C = Config()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KG-n2OiaF4h"
      },
      "source": [
        "2. Define data processing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gToZ5f6haNKs"
      },
      "source": [
        "# Temple resizing function\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import scipy.ndimage.interpolation as inter\n",
        "from scipy.signal import medfilt \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "###################################################################################\n",
        "    \n",
        "    \n",
        "#Rescale to be 64 frames\n",
        "def zoom(p,target_l=64,joints_num=25,joints_dim=3):\n",
        "    l = p.shape[0]\n",
        "    p_new = np.empty([target_l,joints_num,joints_dim]) \n",
        "    for m in range(joints_num):\n",
        "        for n in range(joints_dim):\n",
        "            p[:,m,n] = medfilt(p[:,m,n],3)\n",
        "            p_new[:,m,n] = inter.zoom(p[:,m,n],target_l/l)[:target_l]         \n",
        "    return p_new\n",
        "\n",
        "def sampling_frame(p,C):\n",
        "    full_l = p.shape[0] # full length\n",
        "    if random.uniform(0,1)<0.5: # aligment sampling\n",
        "        valid_l = np.round(np.random.uniform(0.9,1)*full_l)\n",
        "        s = random.randint(0, full_l-int(valid_l))\n",
        "        e = s+valid_l # sample end point\n",
        "        p = p[int(s):int(e),:,:]    \n",
        "    else: # without aligment sampling\n",
        "        valid_l = np.round(np.random.uniform(0.9,1)*full_l)\n",
        "        index = np.sort(np.random.choice(range(0,full_l),int(valid_l),replace=False))\n",
        "        p = p[index,:,:]\n",
        "    p = zoom(p,C.frame_l,C.joint_n,C.joint_d)\n",
        "    return p\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "def get_CG(p,C):\n",
        "    M = []\n",
        "    iu = np.triu_indices(C.joint_n,1,C.joint_n)\n",
        "    for f in range(C.frame_l):\n",
        "        #distance max \n",
        "        d_m = cdist(p[f],np.concatenate([p[f],np.zeros([1,C.joint_d])]),'euclidean')       \n",
        "        d_m = d_m[iu] \n",
        "        M.append(d_m)\n",
        "    M = np.stack(M)   \n",
        "    return M\n",
        "\n",
        "def normlize_range(p):\n",
        "    # normolize to start point, use the center for hand case\n",
        "    p[:,:,0] = p[:,:,0]-np.mean(p[:,:,0])\n",
        "    p[:,:,1] = p[:,:,1]-np.mean(p[:,:,1])\n",
        "    p[:,:,2] = p[:,:,2]-np.mean(p[:,:,2])\n",
        "    return p\n",
        "\n",
        "def cm_analysis(y_true, y_pred, filename, labels, ymap=None, figsize=(8,8)):\n",
        "    \"\"\"\n",
        "    Generate matrix plot of confusion matrix with pretty annotations.\n",
        "    The plot image is saved to disk.\n",
        "    args: \n",
        "      y_true:    true label of the data, with shape (nsamples,)\n",
        "      y_pred:    prediction of the data, with shape (nsamples,)\n",
        "      filename:  filename of figure file to save\n",
        "      labels:    string array, name the order of class labels in the confusion matrix.\n",
        "                 use `clf.classes_` if using scikit-learn models.\n",
        "                 with shape (nclass,).\n",
        "      ymap:      dict: any -> string, length == nclass.\n",
        "                 if not None, map the labels & ys to more understandable strings.\n",
        "                 Caution: original y_true, y_pred and labels must align.\n",
        "      figsize:   the size of the figure plotted.\n",
        "    \"\"\"\n",
        "    if ymap is not None:\n",
        "        y_pred = [ymap[yi] for yi in y_pred]\n",
        "        y_true = [ymap[yi] for yi in y_true]\n",
        "        labels = [ymap[yi] for yi in labels]\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "    cm_perc = cm / cm_sum.astype(float) * 100\n",
        "    annot = np.empty_like(cm).astype(str)\n",
        "    nrows, ncols = cm.shape\n",
        "    for i in range(nrows):\n",
        "        for j in range(ncols):\n",
        "            c = cm[i, j]\n",
        "            p = cm_perc[i, j]\n",
        "            if i == j:\n",
        "                s = cm_sum[i]\n",
        "                #annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
        "                annot[i, j] = '%.1f' % (p)\n",
        "            elif c == 0:\n",
        "                annot[i, j] = ''\n",
        "            else:\n",
        "                #annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
        "                annot[i, j] = '%.1f' % (p)\n",
        "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "    cm.index.name = 'Actual'\n",
        "    cm.columns.name = 'Predicted'\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    sns.heatmap(cm, annot=annot, fmt='', ax=ax, cbar=False, cmap=\"YlGnBu\")\n",
        "    plt.savefig(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDzVwCSYv6bS"
      },
      "source": [
        "3. Define network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVHcN8sGav6m"
      },
      "source": [
        "\n",
        "def poses_diff(x):\n",
        "    H, W = x.get_shape()[1],x.get_shape()[2]\n",
        "    x = tf.subtract(x[:,1:,...],x[:,:-1,...])\n",
        "    x = tf.image.resize(x,size=[H,W]) \n",
        "    return x\n",
        "\n",
        "def pose_motion(P,frame_l):\n",
        "    P_diff_slow = Lambda(lambda x: poses_diff(x))(P)\n",
        "    P_diff_slow = Reshape((frame_l,-1))(P_diff_slow)\n",
        "    P_fast = Lambda(lambda x: x[:,::2,...])(P)\n",
        "    P_diff_fast = Lambda(lambda x: poses_diff(x))(P_fast)\n",
        "    P_diff_fast = Reshape((int(frame_l/2),-1))(P_diff_fast)\n",
        "    return P_diff_slow,P_diff_fast\n",
        "    \n",
        "def c1D(x,filters,kernel):\n",
        "    x = Conv1D(filters, kernel_size=kernel,padding='same',use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    return x\n",
        "\n",
        "def block(x,filters):\n",
        "    x = c1D(x,filters,3)\n",
        "    x = c1D(x,filters,3)\n",
        "    return x\n",
        "    \n",
        "def d1D(x,filters):\n",
        "    x = Dense(filters,use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    return x\n",
        "\n",
        "def build_FM(frame_l=32,joint_n=22,joint_d=2,feat_d=231,filters=16):   \n",
        "    M = Input(shape=(frame_l,feat_d))\n",
        "    P = Input(shape=(frame_l,joint_n,joint_d))\n",
        "    \n",
        "    diff_slow,diff_fast = pose_motion(P,frame_l)\n",
        "    \n",
        "    x = c1D(M,filters*2,1)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    x = c1D(x,filters,3)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    x = c1D(x,filters,1)\n",
        "    x = MaxPooling1D(2)(x)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "\n",
        "    x_d_slow = c1D(diff_slow,filters*2,1)\n",
        "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
        "    x_d_slow = c1D(x_d_slow,filters,3)\n",
        "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
        "    x_d_slow = c1D(x_d_slow,filters,1)\n",
        "    x_d_slow = MaxPool1D(2)(x_d_slow)\n",
        "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
        "        \n",
        "    x_d_fast = c1D(diff_fast,filters*2,1)\n",
        "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
        "    x_d_fast = c1D(x_d_fast,filters,3) \n",
        "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
        "    x_d_fast = c1D(x_d_fast,filters,1) \n",
        "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
        "   \n",
        "    x = concatenate([x,x_d_slow,x_d_fast])\n",
        "    x = block(x,filters*2)\n",
        "    x = MaxPool1D(2)(x)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    \n",
        "    x = block(x,filters*4)\n",
        "    x = MaxPool1D(2)(x)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "\n",
        "    x = block(x,filters*8)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    \n",
        "    return Model(inputs=[M,P],outputs=x)\n",
        "\n",
        "\n",
        "def build_DD_Net(frame_l=32,joint_n=22,joint_d=3,feat_d=231,clc_num=14,filters=16):\n",
        "    M = Input(name='M', shape=(frame_l,feat_d))  \n",
        "    P = Input(name='P', shape=(frame_l,joint_n,joint_d)) \n",
        "    \n",
        "    FM = build_FM(frame_l,joint_n,joint_d,feat_d,filters)\n",
        "    \n",
        "    x = FM([M,P])\n",
        "\n",
        "    x = GlobalMaxPool1D()(x)\n",
        "    \n",
        "    x = d1D(x,128)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = d1D(x,128)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(clc_num, activation='softmax')(x)\n",
        "    \n",
        "    ######################Self-supervised part\n",
        "    model = Model(inputs=[M,P],outputs=x)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8J0YBi3xf7r",
        "outputId": "546ee000-4cb6-42eb-aca9-026f3f095cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "DD_Net = build_DD_Net(C.frame_l,C.joint_n,C.joint_d,C.feat_d,C.clc_coarse,C.filters)\n",
        "DD_Net.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "M (InputLayer)                  [(None, 32, 231)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "P (InputLayer)                  [(None, 32, 22, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "functional_1 (Functional)       (None, 4, 512)       1740160     M[0][0]                          \n",
            "                                                                 P[0][0]                          \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 512)          0           functional_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          65536       global_max_pooling1d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 128)          512         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, 128)          0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 128)          0           leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          16384       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 128)          512         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, 128)          0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 128)          0           leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 14)           1806        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,824,910\n",
            "Trainable params: 1,819,278\n",
            "Non-trainable params: 5,632\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "428x7yhRxyjR"
      },
      "source": [
        "\n",
        "4. Load dataset (download GT_train_1.pkl and  GT_test_1.pkl from github )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPxB--e6UkeI",
        "outputId": "eb051919-d46b-40aa-9497-2e55439e0c30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget https://github.com/fandulu/DD-Net/archive/master.zip\n",
        "!unzip master.zip\n",
        "!rm master.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-19 01:03:07--  https://github.com/fandulu/DD-Net/archive/master.zip\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/fandulu/DD-Net/zip/master [following]\n",
            "--2020-10-19 01:03:07--  https://codeload.github.com/fandulu/DD-Net/zip/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 192.30.255.121\n",
            "Connecting to codeload.github.com (codeload.github.com)|192.30.255.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [        <=>         ]  78.81M  14.2MB/s    in 5.5s    \n",
            "\n",
            "2020-10-19 01:03:13 (14.2 MB/s) - ‘master.zip’ saved [82637231]\n",
            "\n",
            "Archive:  master.zip\n",
            "696855e341b8dc97a3d78e953ad5d2f3616bcf62\n",
            "   creating: DD-Net-master/\n",
            "  inflating: DD-Net-master/.gitignore  \n",
            "   creating: DD-Net-master/JHMDB/\n",
            "  inflating: DD-Net-master/JHMDB/README.md  \n",
            "  inflating: DD-Net-master/JHMDB/jhmdb_1D_heavy.ipynb  \n",
            "  inflating: DD-Net-master/JHMDB/jhmdb_1D_lite.ipynb  \n",
            "  inflating: DD-Net-master/JHMDB/jhmdb_1D_middle.ipynb  \n",
            "  inflating: DD-Net-master/JHMDB/jhmdb_data_preprocessing.ipynb  \n",
            "  inflating: DD-Net-master/JHMDB/utils.py  \n",
            "   creating: DD-Net-master/JHMDB/weights/\n",
            " extracting: DD-Net-master/JHMDB/weights/__init__.py  \n",
            "  inflating: DD-Net-master/LICENSE   \n",
            "  inflating: DD-Net-master/README.md  \n",
            "   creating: DD-Net-master/SHREC/\n",
            "  inflating: DD-Net-master/SHREC/README.md  \n",
            "  inflating: DD-Net-master/SHREC/SHREC_coarse_1D_heavy.ipynb  \n",
            "  inflating: DD-Net-master/SHREC/SHREC_coarse_1D_lite.ipynb  \n",
            "  inflating: DD-Net-master/SHREC/SHREC_data_preprocessing.ipynb  \n",
            "  inflating: DD-Net-master/SHREC/SHREC_fine_1D_heavy.ipynb  \n",
            "  inflating: DD-Net-master/SHREC/SHREC_fine_1D_lite.ipynb  \n",
            "   creating: DD-Net-master/SHREC/images/\n",
            "  inflating: DD-Net-master/SHREC/images/SHREC_14.png  \n",
            "  inflating: DD-Net-master/SHREC/images/SHREC_28.png  \n",
            "  inflating: DD-Net-master/SHREC/utils.py  \n",
            "   creating: DD-Net-master/SHREC/weights/\n",
            " extracting: DD-Net-master/SHREC/weights/.gitkeep  \n",
            " extracting: DD-Net-master/SHREC/weights/__init__.py  \n",
            "   creating: DD-Net-master/data/\n",
            "   creating: DD-Net-master/data/JHMDB/\n",
            "  inflating: DD-Net-master/data/JHMDB/GT_test_1.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/GT_test_2.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/GT_test_3.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/GT_train_1.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/GT_train_2.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/GT_train_3.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/joint_positions.zip  \n",
            "  inflating: DD-Net-master/data/JHMDB/splits.zip  \n",
            "   creating: DD-Net-master/data/SHREC/\n",
            " extracting: DD-Net-master/data/SHREC/__init__.py  \n",
            "  inflating: DD-Net-master/data/SHREC/test.pickle  \n",
            "  inflating: DD-Net-master/data/SHREC/test.pkl  \n",
            "  inflating: DD-Net-master/data/SHREC/train.pickle  \n",
            "  inflating: DD-Net-master/data/SHREC/train.pkl  \n",
            "  inflating: DD-Net-master/demo.png  \n",
            "  inflating: DD-Net-master/look.gif  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kbObgzuHD6f"
      },
      "source": [
        "5. Running codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baR9WIVLye-0",
        "outputId": "afa49701-9509-4f08-b64e-64d4148b62d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Train = pickle.load(open(\"/content/DD-Net-master/data/SHREC/train.pkl\", \"rb\"))\n",
        "Test = pickle.load(open(\"/content/DD-Net-master/data/SHREC/test.pkl\", \"rb\"))\n",
        "\n",
        "X_0 = []\n",
        "X_1 = []\n",
        "Y = []\n",
        "for i in tqdm(range(len(Train['pose']))): \n",
        "    p = np.copy(Train['pose'][i]).reshape([-1,22,3])\n",
        "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
        "    p = normlize_range(p)\n",
        "    \n",
        "    label = np.zeros(C.clc_coarse)\n",
        "    label[Train['coarse_label'][i]-1] = 1   \n",
        "\n",
        "    M = get_CG(p,C)\n",
        "\n",
        "    X_0.append(M)\n",
        "    X_1.append(p)\n",
        "    Y.append(label)\n",
        "\n",
        "X_0 = np.stack(X_0)  \n",
        "X_1 = np.stack(X_1) \n",
        "Y = np.stack(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1960/1960 [00:16<00:00, 121.65it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgD_qxkmihlj",
        "outputId": "fea3e3e5-db90-4d78-8172-12e70a429b7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test_0 = []\n",
        "X_test_1 = []\n",
        "Y_test = []\n",
        "for i in tqdm(range(len(Test['pose']))): \n",
        "    p = np.copy(Test['pose'][i]).reshape([-1,22,3])\n",
        "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
        "    p = normlize_range(p)\n",
        "    \n",
        "    label = np.zeros(C.clc_coarse)\n",
        "    label[Test['coarse_label'][i]-1] = 1   \n",
        "\n",
        "    M = get_CG(p,C)\n",
        "\n",
        "    X_test_0.append(M)\n",
        "    X_test_1.append(p)\n",
        "    Y_test.append(label)\n",
        "\n",
        "X_test_0 = np.stack(X_test_0) \n",
        "X_test_1 = np.stack(X_test_1)  \n",
        "Y_test = np.stack(Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 840/840 [00:06<00:00, 120.30it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRwpfpB9zrB7",
        "outputId": "bea34438-8c9e-4b23-ed8f-2bc68cd64284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# it may takes several times to reach the reported performance\n",
        "lr = 1e-4\n",
        "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=keras.optimizers.Adam(lr),metrics=['accuracy'])\n",
        "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
        "history = DD_Net.fit([X_0,X_1],Y,\n",
        "            batch_size=len(Y),\n",
        "            epochs=400,\n",
        "            verbose=True,\n",
        "            shuffle=True,\n",
        "            callbacks=[lrScheduler],\n",
        "            validation_data=([X_test_0,X_test_1],Y_test)      \n",
        "            )\n",
        "\n",
        "lr = 1e-4\n",
        "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=keras.optimizers.Adam(lr),metrics=['accuracy'])\n",
        "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
        "history = DD_Net.fit([X_0,X_1],Y,\n",
        "            batch_size=len(Y),\n",
        "            epochs=500,\n",
        "            verbose=True,\n",
        "            shuffle=True,\n",
        "            callbacks=[lrScheduler],\n",
        "            validation_data=([X_test_0,X_test_1],Y_test)      \n",
        "            )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0346 - accuracy: 0.9980 - val_loss: 3.1845 - val_accuracy: 0.1060\n",
            "Epoch 2/400\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0399 - accuracy: 0.9954 - val_loss: 3.2060 - val_accuracy: 0.1012\n",
            "Epoch 3/400\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0381 - accuracy: 0.9964 - val_loss: 3.1627 - val_accuracy: 0.1071\n",
            "Epoch 4/400\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0333 - accuracy: 0.9959 - val_loss: 3.0705 - val_accuracy: 0.1202\n",
            "Epoch 5/400\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0356 - accuracy: 0.9980 - val_loss: 2.9895 - val_accuracy: 0.1381\n",
            "Epoch 6/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0331 - accuracy: 0.9980 - val_loss: 2.9559 - val_accuracy: 0.1452\n",
            "Epoch 7/400\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0332 - accuracy: 0.9980 - val_loss: 2.9298 - val_accuracy: 0.1571\n",
            "Epoch 8/400\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0346 - accuracy: 0.9954 - val_loss: 2.9389 - val_accuracy: 0.1631\n",
            "Epoch 9/400\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0341 - accuracy: 0.9964 - val_loss: 2.9565 - val_accuracy: 0.1690\n",
            "Epoch 10/400\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.0273 - accuracy: 0.9995 - val_loss: 2.9553 - val_accuracy: 0.1750\n",
            "Epoch 11/400\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0309 - accuracy: 0.9974 - val_loss: 2.9408 - val_accuracy: 0.1821\n",
            "Epoch 12/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0343 - accuracy: 0.9969 - val_loss: 2.9236 - val_accuracy: 0.1881\n",
            "Epoch 13/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0356 - accuracy: 0.9949 - val_loss: 2.9198 - val_accuracy: 0.1905\n",
            "Epoch 14/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0330 - accuracy: 0.9964 - val_loss: 2.9218 - val_accuracy: 0.1917\n",
            "Epoch 15/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0282 - accuracy: 0.9990 - val_loss: 2.9272 - val_accuracy: 0.1893\n",
            "Epoch 16/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0322 - accuracy: 0.9969 - val_loss: 2.9285 - val_accuracy: 0.1893\n",
            "Epoch 17/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0343 - accuracy: 0.9980 - val_loss: 2.9249 - val_accuracy: 0.1881\n",
            "Epoch 18/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0348 - accuracy: 0.9959 - val_loss: 2.9222 - val_accuracy: 0.1857\n",
            "Epoch 19/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0308 - accuracy: 0.9980 - val_loss: 2.9141 - val_accuracy: 0.1881\n",
            "Epoch 20/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0311 - accuracy: 0.9964 - val_loss: 2.9055 - val_accuracy: 0.1893\n",
            "Epoch 21/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0306 - accuracy: 0.9985 - val_loss: 2.8992 - val_accuracy: 0.1917\n",
            "Epoch 22/400\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0272 - accuracy: 0.9980 - val_loss: 2.8849 - val_accuracy: 0.1929\n",
            "Epoch 23/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0355 - accuracy: 0.9944 - val_loss: 2.8759 - val_accuracy: 0.1940\n",
            "Epoch 24/400\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0271 - accuracy: 0.9985 - val_loss: 2.8644 - val_accuracy: 0.1952\n",
            "Epoch 25/400\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0286 - accuracy: 0.9985 - val_loss: 2.8489 - val_accuracy: 0.1964\n",
            "Epoch 26/400\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0289 - accuracy: 0.9990 - val_loss: 2.8371 - val_accuracy: 0.1940\n",
            "Epoch 27/400\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0283 - accuracy: 0.9974 - val_loss: 2.8219 - val_accuracy: 0.1929\n",
            "Epoch 28/400\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.0309 - accuracy: 0.9980 - val_loss: 2.8102 - val_accuracy: 0.1940\n",
            "Epoch 29/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0290 - accuracy: 0.9969 - val_loss: 2.7998 - val_accuracy: 0.1964\n",
            "Epoch 30/400\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0351 - accuracy: 0.9969 - val_loss: 2.7949 - val_accuracy: 0.1964\n",
            "Epoch 31/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0320 - accuracy: 0.9964 - val_loss: 2.7915 - val_accuracy: 0.1976\n",
            "Epoch 32/400\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0284 - accuracy: 0.9985 - val_loss: 2.7896 - val_accuracy: 0.1976\n",
            "Epoch 33/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0306 - accuracy: 0.9974 - val_loss: 2.7848 - val_accuracy: 0.1988\n",
            "Epoch 34/400\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0308 - accuracy: 0.9990 - val_loss: 2.7811 - val_accuracy: 0.1988\n",
            "Epoch 35/400\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0306 - accuracy: 0.9985 - val_loss: 2.7795 - val_accuracy: 0.2012\n",
            "Epoch 36/400\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0336 - accuracy: 0.9964 - val_loss: 2.7797 - val_accuracy: 0.1988\n",
            "Epoch 37/400\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0326 - accuracy: 0.9974 - val_loss: 2.7826 - val_accuracy: 0.1988\n",
            "Epoch 38/400\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0302 - accuracy: 0.9980 - val_loss: 2.7804 - val_accuracy: 0.2012\n",
            "Epoch 39/400\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0291 - accuracy: 0.9980 - val_loss: 2.7738 - val_accuracy: 0.2036\n",
            "Epoch 40/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0255 - accuracy: 0.9990 - val_loss: 2.7672 - val_accuracy: 0.2048\n",
            "Epoch 41/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0298 - accuracy: 0.9980 - val_loss: 2.7609 - val_accuracy: 0.2060\n",
            "Epoch 42/400\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0316 - accuracy: 0.9980 - val_loss: 2.7501 - val_accuracy: 0.2095\n",
            "Epoch 43/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0273 - accuracy: 0.9990 - val_loss: 2.7407 - val_accuracy: 0.2119\n",
            "Epoch 44/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0310 - accuracy: 0.9964 - val_loss: 2.7301 - val_accuracy: 0.2131\n",
            "Epoch 45/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0266 - accuracy: 0.9980 - val_loss: 2.7191 - val_accuracy: 0.2143\n",
            "Epoch 46/400\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0279 - accuracy: 0.9985 - val_loss: 2.7083 - val_accuracy: 0.2155\n",
            "Epoch 47/400\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.0300 - accuracy: 0.9974 - val_loss: 2.6963 - val_accuracy: 0.2179\n",
            "Epoch 48/400\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.0332 - accuracy: 0.9974 - val_loss: 2.6845 - val_accuracy: 0.2274\n",
            "Epoch 49/400\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0325 - accuracy: 0.9985 - val_loss: 2.6727 - val_accuracy: 0.2286\n",
            "Epoch 50/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0295 - accuracy: 0.9980 - val_loss: 2.6615 - val_accuracy: 0.2321\n",
            "Epoch 51/400\n",
            "1/1 [==============================] - 0s 462ms/step - loss: 0.0299 - accuracy: 0.9969 - val_loss: 2.6501 - val_accuracy: 0.2333\n",
            "Epoch 52/400\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0268 - accuracy: 0.9990 - val_loss: 2.6383 - val_accuracy: 0.2345\n",
            "Epoch 53/400\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.0277 - accuracy: 0.9974 - val_loss: 2.6273 - val_accuracy: 0.2357\n",
            "Epoch 54/400\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0300 - accuracy: 0.9990 - val_loss: 2.6165 - val_accuracy: 0.2381\n",
            "Epoch 55/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0290 - accuracy: 0.9969 - val_loss: 2.6054 - val_accuracy: 0.2429\n",
            "Epoch 56/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0287 - accuracy: 0.9985 - val_loss: 2.5949 - val_accuracy: 0.2440\n",
            "Epoch 57/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0272 - accuracy: 0.9985 - val_loss: 2.5846 - val_accuracy: 0.2476\n",
            "Epoch 58/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0311 - accuracy: 0.9964 - val_loss: 2.5748 - val_accuracy: 0.2488\n",
            "Epoch 59/400\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0307 - accuracy: 0.9980 - val_loss: 2.5644 - val_accuracy: 0.2488\n",
            "Epoch 60/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0332 - accuracy: 0.9969 - val_loss: 2.5538 - val_accuracy: 0.2500\n",
            "Epoch 61/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0319 - accuracy: 0.9969 - val_loss: 2.5428 - val_accuracy: 0.2536\n",
            "Epoch 62/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0305 - accuracy: 0.9969 - val_loss: 2.5326 - val_accuracy: 0.2560\n",
            "Epoch 63/400\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0276 - accuracy: 0.9985 - val_loss: 2.5217 - val_accuracy: 0.2583\n",
            "Epoch 64/400\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0284 - accuracy: 0.9985 - val_loss: 2.5107 - val_accuracy: 0.2619\n",
            "Epoch 65/400\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0282 - accuracy: 0.9995 - val_loss: 2.4991 - val_accuracy: 0.2631\n",
            "Epoch 66/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0282 - accuracy: 0.9985 - val_loss: 2.4875 - val_accuracy: 0.2702\n",
            "Epoch 67/400\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 2.4762 - val_accuracy: 0.2750\n",
            "Epoch 68/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0309 - accuracy: 0.9974 - val_loss: 2.4659 - val_accuracy: 0.2786\n",
            "Epoch 69/400\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0270 - accuracy: 0.9990 - val_loss: 2.4544 - val_accuracy: 0.2833\n",
            "Epoch 70/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0296 - accuracy: 0.9974 - val_loss: 2.4434 - val_accuracy: 0.2845\n",
            "Epoch 71/400\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0267 - accuracy: 0.9985 - val_loss: 2.4321 - val_accuracy: 0.2869\n",
            "Epoch 72/400\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.0287 - accuracy: 0.9990 - val_loss: 2.4191 - val_accuracy: 0.2893\n",
            "Epoch 73/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0275 - accuracy: 0.9990 - val_loss: 2.4061 - val_accuracy: 0.2929\n",
            "Epoch 74/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0308 - accuracy: 0.9974 - val_loss: 2.3940 - val_accuracy: 0.2940\n",
            "Epoch 75/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0275 - accuracy: 0.9969 - val_loss: 2.3822 - val_accuracy: 0.2940\n",
            "Epoch 76/400\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0268 - accuracy: 0.9990 - val_loss: 2.3705 - val_accuracy: 0.2988\n",
            "Epoch 77/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0296 - accuracy: 0.9980 - val_loss: 2.3589 - val_accuracy: 0.3060\n",
            "Epoch 78/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0289 - accuracy: 0.9969 - val_loss: 2.3468 - val_accuracy: 0.3095\n",
            "Epoch 79/400\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0297 - accuracy: 0.9959 - val_loss: 2.3352 - val_accuracy: 0.3167\n",
            "Epoch 80/400\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0308 - accuracy: 0.9969 - val_loss: 2.3235 - val_accuracy: 0.3202\n",
            "Epoch 81/400\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0343 - accuracy: 0.9949 - val_loss: 2.3129 - val_accuracy: 0.3202\n",
            "Epoch 82/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0307 - accuracy: 0.9974 - val_loss: 2.3022 - val_accuracy: 0.3226\n",
            "Epoch 83/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0260 - accuracy: 0.9990 - val_loss: 2.2906 - val_accuracy: 0.3226\n",
            "Epoch 84/400\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0293 - accuracy: 0.9995 - val_loss: 2.2785 - val_accuracy: 0.3250\n",
            "Epoch 85/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0285 - accuracy: 0.9980 - val_loss: 2.2661 - val_accuracy: 0.3286\n",
            "Epoch 86/400\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0274 - accuracy: 0.9980 - val_loss: 2.2536 - val_accuracy: 0.3310\n",
            "Epoch 87/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0269 - accuracy: 0.9980 - val_loss: 2.2410 - val_accuracy: 0.3357\n",
            "Epoch 88/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0307 - accuracy: 0.9969 - val_loss: 2.2291 - val_accuracy: 0.3405\n",
            "Epoch 89/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0311 - accuracy: 0.9969 - val_loss: 2.2164 - val_accuracy: 0.3417\n",
            "Epoch 90/400\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.0275 - accuracy: 0.9990 - val_loss: 2.2041 - val_accuracy: 0.3440\n",
            "Epoch 91/400\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.0261 - accuracy: 0.9990 - val_loss: 2.1921 - val_accuracy: 0.3512\n",
            "Epoch 92/400\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0291 - accuracy: 0.9980 - val_loss: 2.1798 - val_accuracy: 0.3536\n",
            "Epoch 93/400\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0276 - accuracy: 0.9980 - val_loss: 2.1677 - val_accuracy: 0.3560\n",
            "Epoch 94/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0319 - accuracy: 0.9964 - val_loss: 2.1565 - val_accuracy: 0.3607\n",
            "Epoch 95/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0291 - accuracy: 0.9990 - val_loss: 2.1453 - val_accuracy: 0.3631\n",
            "Epoch 96/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0268 - accuracy: 0.9995 - val_loss: 2.1335 - val_accuracy: 0.3655\n",
            "Epoch 97/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0330 - accuracy: 0.9964 - val_loss: 2.1218 - val_accuracy: 0.3679\n",
            "Epoch 98/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0258 - accuracy: 0.9995 - val_loss: 2.1105 - val_accuracy: 0.3702\n",
            "Epoch 99/400\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 2.0993 - val_accuracy: 0.3738\n",
            "Epoch 100/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0280 - accuracy: 0.9974 - val_loss: 2.0878 - val_accuracy: 0.3798\n",
            "Epoch 101/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0319 - accuracy: 0.9974 - val_loss: 2.0761 - val_accuracy: 0.3845\n",
            "Epoch 102/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0331 - accuracy: 0.9959 - val_loss: 2.0636 - val_accuracy: 0.3881\n",
            "Epoch 103/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0279 - accuracy: 0.9969 - val_loss: 2.0515 - val_accuracy: 0.3881\n",
            "Epoch 104/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0237 - accuracy: 0.9990 - val_loss: 2.0399 - val_accuracy: 0.3917\n",
            "Epoch 105/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0305 - accuracy: 0.9980 - val_loss: 2.0278 - val_accuracy: 0.3952\n",
            "Epoch 106/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0311 - accuracy: 0.9959 - val_loss: 2.0148 - val_accuracy: 0.3964\n",
            "Epoch 107/400\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0270 - accuracy: 0.9990 - val_loss: 2.0026 - val_accuracy: 0.4012\n",
            "Epoch 108/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0260 - accuracy: 0.9985 - val_loss: 1.9896 - val_accuracy: 0.4071\n",
            "Epoch 109/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0258 - accuracy: 0.9980 - val_loss: 1.9769 - val_accuracy: 0.4143\n",
            "Epoch 110/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0293 - accuracy: 0.9990 - val_loss: 1.9643 - val_accuracy: 0.4214\n",
            "Epoch 111/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0276 - accuracy: 0.9985 - val_loss: 1.9524 - val_accuracy: 0.4238\n",
            "Epoch 112/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0274 - accuracy: 0.9985 - val_loss: 1.9401 - val_accuracy: 0.4274\n",
            "Epoch 113/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0267 - accuracy: 0.9985 - val_loss: 1.9274 - val_accuracy: 0.4310\n",
            "Epoch 114/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0310 - accuracy: 0.9959 - val_loss: 1.9145 - val_accuracy: 0.4321\n",
            "Epoch 115/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0275 - accuracy: 0.9980 - val_loss: 1.9016 - val_accuracy: 0.4357\n",
            "Epoch 116/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0262 - accuracy: 0.9985 - val_loss: 1.8894 - val_accuracy: 0.4393\n",
            "Epoch 117/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0294 - accuracy: 0.9980 - val_loss: 1.8774 - val_accuracy: 0.4417\n",
            "Epoch 118/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0277 - accuracy: 0.9969 - val_loss: 1.8653 - val_accuracy: 0.4429\n",
            "Epoch 119/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0290 - accuracy: 0.9974 - val_loss: 1.8527 - val_accuracy: 0.4464\n",
            "Epoch 120/400\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0273 - accuracy: 0.9985 - val_loss: 1.8397 - val_accuracy: 0.4476\n",
            "Epoch 121/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0296 - accuracy: 0.9985 - val_loss: 1.8273 - val_accuracy: 0.4548\n",
            "Epoch 122/400\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0258 - accuracy: 0.9985 - val_loss: 1.8148 - val_accuracy: 0.4571\n",
            "Epoch 123/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0284 - accuracy: 0.9990 - val_loss: 1.8026 - val_accuracy: 0.4619\n",
            "Epoch 124/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0269 - accuracy: 0.9980 - val_loss: 1.7907 - val_accuracy: 0.4655\n",
            "Epoch 125/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0273 - accuracy: 0.9985 - val_loss: 1.7788 - val_accuracy: 0.4679\n",
            "Epoch 126/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0276 - accuracy: 0.9990 - val_loss: 1.7670 - val_accuracy: 0.4679\n",
            "Epoch 127/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0303 - accuracy: 0.9985 - val_loss: 1.7550 - val_accuracy: 0.4690\n",
            "Epoch 128/400\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0301 - accuracy: 0.9985 - val_loss: 1.7422 - val_accuracy: 0.4714\n",
            "Epoch 129/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0303 - accuracy: 0.9985 - val_loss: 1.7298 - val_accuracy: 0.4738\n",
            "Epoch 130/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0275 - accuracy: 0.9980 - val_loss: 1.7176 - val_accuracy: 0.4774\n",
            "Epoch 131/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0257 - accuracy: 0.9990 - val_loss: 1.7049 - val_accuracy: 0.4774\n",
            "Epoch 132/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 1.6927 - val_accuracy: 0.4810\n",
            "Epoch 133/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0260 - accuracy: 0.9990 - val_loss: 1.6805 - val_accuracy: 0.4857\n",
            "Epoch 134/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0286 - accuracy: 0.9974 - val_loss: 1.6682 - val_accuracy: 0.4881\n",
            "Epoch 135/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0289 - accuracy: 0.9980 - val_loss: 1.6556 - val_accuracy: 0.4905\n",
            "Epoch 136/400\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0280 - accuracy: 0.9974 - val_loss: 1.6435 - val_accuracy: 0.4940\n",
            "Epoch 137/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0290 - accuracy: 0.9980 - val_loss: 1.6311 - val_accuracy: 0.5048\n",
            "Epoch 138/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0289 - accuracy: 0.9964 - val_loss: 1.6187 - val_accuracy: 0.5060\n",
            "Epoch 139/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0307 - accuracy: 0.9980 - val_loss: 1.6062 - val_accuracy: 0.5131\n",
            "Epoch 140/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0287 - accuracy: 0.9980 - val_loss: 1.5937 - val_accuracy: 0.5167\n",
            "Epoch 141/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0302 - accuracy: 0.9969 - val_loss: 1.5810 - val_accuracy: 0.5202\n",
            "Epoch 142/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0289 - accuracy: 0.9990 - val_loss: 1.5681 - val_accuracy: 0.5250\n",
            "Epoch 143/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0293 - accuracy: 0.9980 - val_loss: 1.5558 - val_accuracy: 0.5298\n",
            "Epoch 144/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0268 - accuracy: 0.9985 - val_loss: 1.5429 - val_accuracy: 0.5298\n",
            "Epoch 145/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0257 - accuracy: 0.9990 - val_loss: 1.5293 - val_accuracy: 0.5333\n",
            "Epoch 146/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0297 - accuracy: 0.9964 - val_loss: 1.5166 - val_accuracy: 0.5345\n",
            "Epoch 147/400\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0287 - accuracy: 0.9980 - val_loss: 1.5041 - val_accuracy: 0.5393\n",
            "Epoch 148/400\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0282 - accuracy: 0.9980 - val_loss: 1.4916 - val_accuracy: 0.5429\n",
            "Epoch 149/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0298 - accuracy: 0.9969 - val_loss: 1.4793 - val_accuracy: 0.5488\n",
            "Epoch 150/400\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0330 - accuracy: 0.9969 - val_loss: 1.4668 - val_accuracy: 0.5524\n",
            "Epoch 151/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0277 - accuracy: 0.9985 - val_loss: 1.4546 - val_accuracy: 0.5560\n",
            "Epoch 152/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0253 - accuracy: 0.9990 - val_loss: 1.4426 - val_accuracy: 0.5607\n",
            "Epoch 153/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0246 - accuracy: 0.9990 - val_loss: 1.4312 - val_accuracy: 0.5631\n",
            "Epoch 154/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0240 - accuracy: 0.9985 - val_loss: 1.4202 - val_accuracy: 0.5643\n",
            "Epoch 155/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0276 - accuracy: 0.9995 - val_loss: 1.4095 - val_accuracy: 0.5643\n",
            "Epoch 156/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0284 - accuracy: 0.9980 - val_loss: 1.3983 - val_accuracy: 0.5702\n",
            "Epoch 157/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0266 - accuracy: 0.9985 - val_loss: 1.3871 - val_accuracy: 0.5738\n",
            "Epoch 158/400\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0268 - accuracy: 0.9990 - val_loss: 1.3760 - val_accuracy: 0.5762\n",
            "Epoch 159/400\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0289 - accuracy: 0.9964 - val_loss: 1.3650 - val_accuracy: 0.5845\n",
            "Epoch 160/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0303 - accuracy: 0.9980 - val_loss: 1.3542 - val_accuracy: 0.5869\n",
            "Epoch 161/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0279 - accuracy: 0.9980 - val_loss: 1.3432 - val_accuracy: 0.5893\n",
            "Epoch 162/400\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0344 - accuracy: 0.9974 - val_loss: 1.3327 - val_accuracy: 0.5964\n",
            "Epoch 163/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0252 - accuracy: 0.9985 - val_loss: 1.3219 - val_accuracy: 0.5976\n",
            "Epoch 164/400\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.0267 - accuracy: 0.9980 - val_loss: 1.3112 - val_accuracy: 0.5988\n",
            "Epoch 165/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0259 - accuracy: 0.9985 - val_loss: 1.3008 - val_accuracy: 0.6036\n",
            "Epoch 166/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0279 - accuracy: 0.9980 - val_loss: 1.2902 - val_accuracy: 0.6071\n",
            "Epoch 167/400\n",
            "1/1 [==============================] - 1s 522ms/step - loss: 0.0314 - accuracy: 0.9959 - val_loss: 1.2795 - val_accuracy: 0.6119\n",
            "Epoch 168/400\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.0315 - accuracy: 0.9964 - val_loss: 1.2689 - val_accuracy: 0.6131\n",
            "Epoch 169/400\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0239 - accuracy: 0.9995 - val_loss: 1.2587 - val_accuracy: 0.6179\n",
            "Epoch 170/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0314 - accuracy: 0.9974 - val_loss: 1.2484 - val_accuracy: 0.6190\n",
            "Epoch 171/400\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0269 - accuracy: 0.9964 - val_loss: 1.2382 - val_accuracy: 0.6214\n",
            "Epoch 172/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0284 - accuracy: 0.9969 - val_loss: 1.2280 - val_accuracy: 0.6238\n",
            "Epoch 173/400\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.0239 - accuracy: 0.9990 - val_loss: 1.2177 - val_accuracy: 0.6274\n",
            "Epoch 174/400\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.0268 - accuracy: 0.9990 - val_loss: 1.2074 - val_accuracy: 0.6333\n",
            "Epoch 175/400\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.0261 - accuracy: 0.9974 - val_loss: 1.1977 - val_accuracy: 0.6345\n",
            "Epoch 176/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0283 - accuracy: 0.9980 - val_loss: 1.1883 - val_accuracy: 0.6393\n",
            "Epoch 177/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0252 - accuracy: 0.9985 - val_loss: 1.1790 - val_accuracy: 0.6405\n",
            "Epoch 178/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0313 - accuracy: 0.9974 - val_loss: 1.1698 - val_accuracy: 0.6429\n",
            "Epoch 179/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0307 - accuracy: 0.9974 - val_loss: 1.1604 - val_accuracy: 0.6464\n",
            "Epoch 180/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0269 - accuracy: 0.9985 - val_loss: 1.1513 - val_accuracy: 0.6524\n",
            "Epoch 181/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0312 - accuracy: 0.9980 - val_loss: 1.1421 - val_accuracy: 0.6548\n",
            "Epoch 182/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0268 - accuracy: 0.9990 - val_loss: 1.1329 - val_accuracy: 0.6571\n",
            "Epoch 183/400\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0283 - accuracy: 0.9969 - val_loss: 1.1237 - val_accuracy: 0.6619\n",
            "Epoch 184/400\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0272 - accuracy: 0.9985 - val_loss: 1.1147 - val_accuracy: 0.6631\n",
            "Epoch 185/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0311 - accuracy: 0.9980 - val_loss: 1.1051 - val_accuracy: 0.6667\n",
            "Epoch 186/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0253 - accuracy: 0.9990 - val_loss: 1.0961 - val_accuracy: 0.6679\n",
            "Epoch 187/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 1.0868 - val_accuracy: 0.6702\n",
            "Epoch 188/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0274 - accuracy: 0.9974 - val_loss: 1.0777 - val_accuracy: 0.6726\n",
            "Epoch 189/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0305 - accuracy: 0.9964 - val_loss: 1.0684 - val_accuracy: 0.6786\n",
            "Epoch 190/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0271 - accuracy: 0.9974 - val_loss: 1.0586 - val_accuracy: 0.6881\n",
            "Epoch 191/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0261 - accuracy: 0.9985 - val_loss: 1.0490 - val_accuracy: 0.6893\n",
            "Epoch 192/400\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0306 - accuracy: 0.9985 - val_loss: 1.0395 - val_accuracy: 0.6893\n",
            "Epoch 193/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0293 - accuracy: 0.9969 - val_loss: 1.0300 - val_accuracy: 0.6929\n",
            "Epoch 194/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0301 - accuracy: 0.9969 - val_loss: 1.0208 - val_accuracy: 0.6940\n",
            "Epoch 195/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0305 - accuracy: 0.9974 - val_loss: 1.0117 - val_accuracy: 0.6952\n",
            "Epoch 196/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0274 - accuracy: 0.9980 - val_loss: 1.0024 - val_accuracy: 0.6976\n",
            "Epoch 197/400\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0259 - accuracy: 0.9990 - val_loss: 0.9931 - val_accuracy: 0.7012\n",
            "Epoch 198/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0253 - accuracy: 0.9995 - val_loss: 0.9838 - val_accuracy: 0.7012\n",
            "Epoch 199/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0264 - accuracy: 0.9985 - val_loss: 0.9747 - val_accuracy: 0.7012\n",
            "Epoch 200/400\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0276 - accuracy: 0.9980 - val_loss: 0.9653 - val_accuracy: 0.7048\n",
            "Epoch 201/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0289 - accuracy: 0.9980 - val_loss: 0.9565 - val_accuracy: 0.7048\n",
            "Epoch 202/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0238 - accuracy: 0.9995 - val_loss: 0.9474 - val_accuracy: 0.7048\n",
            "Epoch 203/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0272 - accuracy: 0.9974 - val_loss: 0.9386 - val_accuracy: 0.7095\n",
            "Epoch 204/400\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.9301 - val_accuracy: 0.7131\n",
            "Epoch 205/400\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0290 - accuracy: 0.9974 - val_loss: 0.9215 - val_accuracy: 0.7179\n",
            "Epoch 206/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0267 - accuracy: 0.9990 - val_loss: 0.9126 - val_accuracy: 0.7202\n",
            "Epoch 207/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0298 - accuracy: 0.9974 - val_loss: 0.9037 - val_accuracy: 0.7250\n",
            "Epoch 208/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0284 - accuracy: 0.9985 - val_loss: 0.8948 - val_accuracy: 0.7286\n",
            "Epoch 209/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.8860 - val_accuracy: 0.7333\n",
            "Epoch 210/400\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0270 - accuracy: 0.9985 - val_loss: 0.8774 - val_accuracy: 0.7357\n",
            "Epoch 211/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0264 - accuracy: 0.9990 - val_loss: 0.8689 - val_accuracy: 0.7381\n",
            "Epoch 212/400\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0245 - accuracy: 0.9995 - val_loss: 0.8604 - val_accuracy: 0.7405\n",
            "Epoch 213/400\n",
            "1/1 [==============================] - 0s 500ms/step - loss: 0.0265 - accuracy: 0.9995 - val_loss: 0.8518 - val_accuracy: 0.7417\n",
            "Epoch 214/400\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0257 - accuracy: 0.9985 - val_loss: 0.8430 - val_accuracy: 0.7476\n",
            "Epoch 215/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0303 - accuracy: 0.9980 - val_loss: 0.8342 - val_accuracy: 0.7488\n",
            "Epoch 216/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0258 - accuracy: 0.9985 - val_loss: 0.8256 - val_accuracy: 0.7512\n",
            "Epoch 217/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0263 - accuracy: 0.9995 - val_loss: 0.8178 - val_accuracy: 0.7536\n",
            "Epoch 218/400\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.0256 - accuracy: 0.9995 - val_loss: 0.8100 - val_accuracy: 0.7548\n",
            "Epoch 219/400\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0276 - accuracy: 0.9980 - val_loss: 0.8025 - val_accuracy: 0.7560\n",
            "Epoch 220/400\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0275 - accuracy: 0.9974 - val_loss: 0.7950 - val_accuracy: 0.7619\n",
            "Epoch 221/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0272 - accuracy: 0.9980 - val_loss: 0.7872 - val_accuracy: 0.7631\n",
            "Epoch 222/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0273 - accuracy: 0.9969 - val_loss: 0.7794 - val_accuracy: 0.7667\n",
            "Epoch 223/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0306 - accuracy: 0.9969 - val_loss: 0.7721 - val_accuracy: 0.7667\n",
            "Epoch 224/400\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0267 - accuracy: 0.9980 - val_loss: 0.7652 - val_accuracy: 0.7667\n",
            "Epoch 225/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0309 - accuracy: 0.9985 - val_loss: 0.7583 - val_accuracy: 0.7690\n",
            "Epoch 226/400\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0268 - accuracy: 0.9969 - val_loss: 0.7511 - val_accuracy: 0.7714\n",
            "Epoch 227/400\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0311 - accuracy: 0.9969 - val_loss: 0.7443 - val_accuracy: 0.7726\n",
            "Epoch 228/400\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0236 - accuracy: 0.9990 - val_loss: 0.7374 - val_accuracy: 0.7762\n",
            "Epoch 229/400\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0275 - accuracy: 0.9980 - val_loss: 0.7309 - val_accuracy: 0.7762\n",
            "Epoch 230/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0276 - accuracy: 0.9980 - val_loss: 0.7245 - val_accuracy: 0.7774\n",
            "Epoch 231/400\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0249 - accuracy: 0.9995 - val_loss: 0.7183 - val_accuracy: 0.7798\n",
            "Epoch 232/400\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0279 - accuracy: 0.9980 - val_loss: 0.7121 - val_accuracy: 0.7833\n",
            "Epoch 233/400\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0310 - accuracy: 0.9974 - val_loss: 0.7056 - val_accuracy: 0.7833\n",
            "Epoch 234/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0292 - accuracy: 0.9974 - val_loss: 0.6996 - val_accuracy: 0.7881\n",
            "Epoch 235/400\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.0253 - accuracy: 0.9974 - val_loss: 0.6936 - val_accuracy: 0.7893\n",
            "Epoch 236/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0285 - accuracy: 0.9985 - val_loss: 0.6871 - val_accuracy: 0.7905\n",
            "Epoch 237/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0289 - accuracy: 0.9980 - val_loss: 0.6811 - val_accuracy: 0.7905\n",
            "Epoch 238/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0255 - accuracy: 0.9995 - val_loss: 0.6750 - val_accuracy: 0.7905\n",
            "Epoch 239/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0286 - accuracy: 0.9985 - val_loss: 0.6688 - val_accuracy: 0.7905\n",
            "Epoch 240/400\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0253 - accuracy: 0.9995 - val_loss: 0.6626 - val_accuracy: 0.7905\n",
            "Epoch 241/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0300 - accuracy: 0.9969 - val_loss: 0.6560 - val_accuracy: 0.7917\n",
            "Epoch 242/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0264 - accuracy: 0.9964 - val_loss: 0.6495 - val_accuracy: 0.7976\n",
            "Epoch 243/400\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.0257 - accuracy: 0.9990 - val_loss: 0.6429 - val_accuracy: 0.8036\n",
            "Epoch 244/400\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0296 - accuracy: 0.9964 - val_loss: 0.6363 - val_accuracy: 0.8060\n",
            "Epoch 245/400\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0284 - accuracy: 0.9985 - val_loss: 0.6303 - val_accuracy: 0.8060\n",
            "Epoch 246/400\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0297 - accuracy: 0.9974 - val_loss: 0.6241 - val_accuracy: 0.8107\n",
            "Epoch 247/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0274 - accuracy: 0.9969 - val_loss: 0.6182 - val_accuracy: 0.8143\n",
            "Epoch 248/400\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0257 - accuracy: 0.9980 - val_loss: 0.6126 - val_accuracy: 0.8131\n",
            "Epoch 249/400\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0290 - accuracy: 0.9969 - val_loss: 0.6068 - val_accuracy: 0.8167\n",
            "Epoch 250/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0307 - accuracy: 0.9974 - val_loss: 0.6011 - val_accuracy: 0.8179\n",
            "Epoch 251/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0239 - accuracy: 0.9995 - val_loss: 0.5953 - val_accuracy: 0.8202\n",
            "Epoch 252/400\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0267 - accuracy: 0.9974 - val_loss: 0.5897 - val_accuracy: 0.8226\n",
            "Epoch 253/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0264 - accuracy: 0.9980 - val_loss: 0.5841 - val_accuracy: 0.8238\n",
            "Epoch 254/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0297 - accuracy: 0.9969 - val_loss: 0.5784 - val_accuracy: 0.8238\n",
            "Epoch 255/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0256 - accuracy: 0.9990 - val_loss: 0.5726 - val_accuracy: 0.8262\n",
            "Epoch 256/400\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0249 - accuracy: 0.9980 - val_loss: 0.5672 - val_accuracy: 0.8298\n",
            "Epoch 257/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0261 - accuracy: 0.9990 - val_loss: 0.5619 - val_accuracy: 0.8310\n",
            "Epoch 258/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0238 - accuracy: 0.9990 - val_loss: 0.5563 - val_accuracy: 0.8310\n",
            "Epoch 259/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0249 - accuracy: 0.9980 - val_loss: 0.5509 - val_accuracy: 0.8321\n",
            "Epoch 260/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0277 - accuracy: 0.9985 - val_loss: 0.5456 - val_accuracy: 0.8333\n",
            "Epoch 261/400\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0266 - accuracy: 0.9980 - val_loss: 0.5400 - val_accuracy: 0.8345\n",
            "Epoch 262/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0295 - accuracy: 0.9969 - val_loss: 0.5346 - val_accuracy: 0.8357\n",
            "Epoch 263/400\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0286 - accuracy: 0.9980 - val_loss: 0.5294 - val_accuracy: 0.8393\n",
            "Epoch 264/400\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0254 - accuracy: 0.9985 - val_loss: 0.5241 - val_accuracy: 0.8417\n",
            "Epoch 265/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0296 - accuracy: 0.9990 - val_loss: 0.5188 - val_accuracy: 0.8440\n",
            "Epoch 266/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0264 - accuracy: 0.9990 - val_loss: 0.5140 - val_accuracy: 0.8452\n",
            "Epoch 267/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0261 - accuracy: 0.9985 - val_loss: 0.5088 - val_accuracy: 0.8476\n",
            "Epoch 268/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0253 - accuracy: 0.9980 - val_loss: 0.5034 - val_accuracy: 0.8512\n",
            "Epoch 269/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0282 - accuracy: 0.9985 - val_loss: 0.4985 - val_accuracy: 0.8524\n",
            "Epoch 270/400\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0266 - accuracy: 0.9990 - val_loss: 0.4934 - val_accuracy: 0.8548\n",
            "Epoch 271/400\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.0287 - accuracy: 0.9974 - val_loss: 0.4882 - val_accuracy: 0.8548\n",
            "Epoch 272/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0321 - accuracy: 0.9964 - val_loss: 0.4833 - val_accuracy: 0.8548\n",
            "Epoch 273/400\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0260 - accuracy: 0.9959 - val_loss: 0.4786 - val_accuracy: 0.8560\n",
            "Epoch 274/400\n",
            "1/1 [==============================] - 0s 498ms/step - loss: 0.0271 - accuracy: 0.9990 - val_loss: 0.4740 - val_accuracy: 0.8560\n",
            "Epoch 275/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0296 - accuracy: 0.9974 - val_loss: 0.4696 - val_accuracy: 0.8560\n",
            "Epoch 276/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0243 - accuracy: 0.9985 - val_loss: 0.4652 - val_accuracy: 0.8560\n",
            "Epoch 277/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0255 - accuracy: 0.9995 - val_loss: 0.4609 - val_accuracy: 0.8583\n",
            "Epoch 278/400\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0275 - accuracy: 0.9974 - val_loss: 0.4567 - val_accuracy: 0.8607\n",
            "Epoch 279/400\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.8619\n",
            "Epoch 280/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0271 - accuracy: 0.9980 - val_loss: 0.4484 - val_accuracy: 0.8619\n",
            "Epoch 281/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0291 - accuracy: 0.9969 - val_loss: 0.4443 - val_accuracy: 0.8643\n",
            "Epoch 282/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0248 - accuracy: 0.9980 - val_loss: 0.4401 - val_accuracy: 0.8655\n",
            "Epoch 283/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0248 - accuracy: 0.9995 - val_loss: 0.4357 - val_accuracy: 0.8667\n",
            "Epoch 284/400\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0294 - accuracy: 0.9980 - val_loss: 0.4315 - val_accuracy: 0.8667\n",
            "Epoch 285/400\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0276 - accuracy: 0.9969 - val_loss: 0.4271 - val_accuracy: 0.8679\n",
            "Epoch 286/400\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.0267 - accuracy: 0.9990 - val_loss: 0.4227 - val_accuracy: 0.8679\n",
            "Epoch 287/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0285 - accuracy: 0.9980 - val_loss: 0.4184 - val_accuracy: 0.8679\n",
            "Epoch 288/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0233 - accuracy: 0.9985 - val_loss: 0.4140 - val_accuracy: 0.8690\n",
            "Epoch 289/400\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0251 - accuracy: 0.9990 - val_loss: 0.4099 - val_accuracy: 0.8702\n",
            "Epoch 290/400\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.0248 - accuracy: 0.9990 - val_loss: 0.4057 - val_accuracy: 0.8702\n",
            "Epoch 291/400\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0265 - accuracy: 0.9980 - val_loss: 0.4015 - val_accuracy: 0.8714\n",
            "Epoch 292/400\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0254 - accuracy: 0.9995 - val_loss: 0.3972 - val_accuracy: 0.8714\n",
            "Epoch 293/400\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.0254 - accuracy: 0.9995 - val_loss: 0.3932 - val_accuracy: 0.8714\n",
            "Epoch 294/400\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0237 - accuracy: 0.9985 - val_loss: 0.3891 - val_accuracy: 0.8726\n",
            "Epoch 295/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0241 - accuracy: 0.9995 - val_loss: 0.3853 - val_accuracy: 0.8738\n",
            "Epoch 296/400\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0261 - accuracy: 0.9969 - val_loss: 0.3815 - val_accuracy: 0.8738\n",
            "Epoch 297/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0280 - accuracy: 0.9980 - val_loss: 0.3777 - val_accuracy: 0.8738\n",
            "Epoch 298/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0255 - accuracy: 0.9985 - val_loss: 0.3738 - val_accuracy: 0.8750\n",
            "Epoch 299/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0255 - accuracy: 0.9980 - val_loss: 0.3697 - val_accuracy: 0.8774\n",
            "Epoch 300/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0274 - accuracy: 0.9990 - val_loss: 0.3657 - val_accuracy: 0.8786\n",
            "Epoch 301/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0255 - accuracy: 0.9985 - val_loss: 0.3618 - val_accuracy: 0.8798\n",
            "Epoch 302/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0254 - accuracy: 0.9980 - val_loss: 0.3579 - val_accuracy: 0.8798\n",
            "Epoch 303/400\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.8810\n",
            "Epoch 304/400\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.0276 - accuracy: 0.9980 - val_loss: 0.3505 - val_accuracy: 0.8810\n",
            "Epoch 305/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0264 - accuracy: 0.9980 - val_loss: 0.3469 - val_accuracy: 0.8845\n",
            "Epoch 306/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0244 - accuracy: 0.9990 - val_loss: 0.3437 - val_accuracy: 0.8869\n",
            "Epoch 307/400\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0270 - accuracy: 0.9974 - val_loss: 0.3407 - val_accuracy: 0.8893\n",
            "Epoch 308/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0264 - accuracy: 0.9974 - val_loss: 0.3378 - val_accuracy: 0.8905\n",
            "Epoch 309/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0253 - accuracy: 0.9990 - val_loss: 0.3348 - val_accuracy: 0.8940\n",
            "Epoch 310/400\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0251 - accuracy: 0.9985 - val_loss: 0.3319 - val_accuracy: 0.8952\n",
            "Epoch 311/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0239 - accuracy: 0.9995 - val_loss: 0.3290 - val_accuracy: 0.9000\n",
            "Epoch 312/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0240 - accuracy: 0.9995 - val_loss: 0.3261 - val_accuracy: 0.9000\n",
            "Epoch 313/400\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0266 - accuracy: 0.9969 - val_loss: 0.3233 - val_accuracy: 0.9012\n",
            "Epoch 314/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0293 - accuracy: 0.9974 - val_loss: 0.3208 - val_accuracy: 0.9024\n",
            "Epoch 315/400\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0292 - accuracy: 0.9969 - val_loss: 0.3183 - val_accuracy: 0.9024\n",
            "Epoch 316/400\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0274 - accuracy: 0.9980 - val_loss: 0.3161 - val_accuracy: 0.9036\n",
            "Epoch 317/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0310 - accuracy: 0.9980 - val_loss: 0.3137 - val_accuracy: 0.9048\n",
            "Epoch 318/400\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0252 - accuracy: 0.9985 - val_loss: 0.3114 - val_accuracy: 0.9060\n",
            "Epoch 319/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0221 - accuracy: 0.9990 - val_loss: 0.3091 - val_accuracy: 0.9083\n",
            "Epoch 320/400\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0252 - accuracy: 0.9985 - val_loss: 0.3068 - val_accuracy: 0.9095\n",
            "Epoch 321/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0243 - accuracy: 0.9980 - val_loss: 0.3044 - val_accuracy: 0.9095\n",
            "Epoch 322/400\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0270 - accuracy: 0.9985 - val_loss: 0.3020 - val_accuracy: 0.9107\n",
            "Epoch 323/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0266 - accuracy: 0.9969 - val_loss: 0.2996 - val_accuracy: 0.9119\n",
            "Epoch 324/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0228 - accuracy: 0.9985 - val_loss: 0.2973 - val_accuracy: 0.9143\n",
            "Epoch 325/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0264 - accuracy: 0.9980 - val_loss: 0.2949 - val_accuracy: 0.9155\n",
            "Epoch 326/400\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.0278 - accuracy: 0.9980 - val_loss: 0.2927 - val_accuracy: 0.9155\n",
            "Epoch 327/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0282 - accuracy: 0.9974 - val_loss: 0.2906 - val_accuracy: 0.9155\n",
            "Epoch 328/400\n",
            "1/1 [==============================] - 0s 495ms/step - loss: 0.0275 - accuracy: 0.9985 - val_loss: 0.2885 - val_accuracy: 0.9155\n",
            "Epoch 329/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0252 - accuracy: 0.9985 - val_loss: 0.2865 - val_accuracy: 0.9155\n",
            "Epoch 330/400\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0305 - accuracy: 0.9969 - val_loss: 0.2845 - val_accuracy: 0.9167\n",
            "Epoch 331/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0286 - accuracy: 0.9969 - val_loss: 0.2826 - val_accuracy: 0.9167\n",
            "Epoch 332/400\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0328 - accuracy: 0.9959 - val_loss: 0.2809 - val_accuracy: 0.9167\n",
            "Epoch 333/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0243 - accuracy: 0.9980 - val_loss: 0.2792 - val_accuracy: 0.9167\n",
            "Epoch 334/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0283 - accuracy: 0.9969 - val_loss: 0.2774 - val_accuracy: 0.9167\n",
            "Epoch 335/400\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.0261 - accuracy: 0.9974 - val_loss: 0.2755 - val_accuracy: 0.9167\n",
            "Epoch 336/400\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.0267 - accuracy: 0.9985 - val_loss: 0.2737 - val_accuracy: 0.9167\n",
            "Epoch 337/400\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0267 - accuracy: 0.9980 - val_loss: 0.2718 - val_accuracy: 0.9190\n",
            "Epoch 338/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0301 - accuracy: 0.9964 - val_loss: 0.2697 - val_accuracy: 0.9202\n",
            "Epoch 339/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0271 - accuracy: 0.9969 - val_loss: 0.2677 - val_accuracy: 0.9226\n",
            "Epoch 340/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0245 - accuracy: 0.9985 - val_loss: 0.2657 - val_accuracy: 0.9250\n",
            "Epoch 341/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0242 - accuracy: 0.9980 - val_loss: 0.2639 - val_accuracy: 0.9250\n",
            "Epoch 342/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0269 - accuracy: 0.9985 - val_loss: 0.2621 - val_accuracy: 0.9250\n",
            "Epoch 343/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0282 - accuracy: 0.9980 - val_loss: 0.2603 - val_accuracy: 0.9274\n",
            "Epoch 344/400\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0275 - accuracy: 0.9974 - val_loss: 0.2586 - val_accuracy: 0.9274\n",
            "Epoch 345/400\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0233 - accuracy: 0.9995 - val_loss: 0.2569 - val_accuracy: 0.9298\n",
            "Epoch 346/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0219 - accuracy: 0.9995 - val_loss: 0.2551 - val_accuracy: 0.9298\n",
            "Epoch 347/400\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0263 - accuracy: 0.9985 - val_loss: 0.2534 - val_accuracy: 0.9298\n",
            "Epoch 348/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0273 - accuracy: 0.9985 - val_loss: 0.2517 - val_accuracy: 0.9298\n",
            "Epoch 349/400\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0267 - accuracy: 0.9974 - val_loss: 0.2499 - val_accuracy: 0.9298\n",
            "Epoch 350/400\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0234 - accuracy: 0.9995 - val_loss: 0.2482 - val_accuracy: 0.9310\n",
            "Epoch 351/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0243 - accuracy: 0.9990 - val_loss: 0.2465 - val_accuracy: 0.9321\n",
            "Epoch 352/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0260 - accuracy: 0.9980 - val_loss: 0.2447 - val_accuracy: 0.9321\n",
            "Epoch 353/400\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0259 - accuracy: 0.9985 - val_loss: 0.2431 - val_accuracy: 0.9310\n",
            "Epoch 354/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0264 - accuracy: 0.9990 - val_loss: 0.2415 - val_accuracy: 0.9333\n",
            "Epoch 355/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0231 - accuracy: 0.9985 - val_loss: 0.2400 - val_accuracy: 0.9333\n",
            "Epoch 356/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0256 - accuracy: 0.9980 - val_loss: 0.2385 - val_accuracy: 0.9333\n",
            "Epoch 357/400\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0257 - accuracy: 0.9990 - val_loss: 0.2369 - val_accuracy: 0.9333\n",
            "Epoch 358/400\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.0261 - accuracy: 0.9995 - val_loss: 0.2354 - val_accuracy: 0.9333\n",
            "Epoch 359/400\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0261 - accuracy: 0.9969 - val_loss: 0.2339 - val_accuracy: 0.9345\n",
            "Epoch 360/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0230 - accuracy: 0.9985 - val_loss: 0.2324 - val_accuracy: 0.9357\n",
            "Epoch 361/400\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0246 - accuracy: 0.9974 - val_loss: 0.2309 - val_accuracy: 0.9357\n",
            "Epoch 362/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0279 - accuracy: 0.9985 - val_loss: 0.2296 - val_accuracy: 0.9357\n",
            "Epoch 363/400\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0270 - accuracy: 0.9985 - val_loss: 0.2282 - val_accuracy: 0.9369\n",
            "Epoch 364/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0213 - accuracy: 0.9990 - val_loss: 0.2268 - val_accuracy: 0.9369\n",
            "Epoch 365/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0248 - accuracy: 0.9990 - val_loss: 0.2255 - val_accuracy: 0.9369\n",
            "Epoch 366/400\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0241 - accuracy: 0.9995 - val_loss: 0.2242 - val_accuracy: 0.9369\n",
            "Epoch 367/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0261 - accuracy: 0.9985 - val_loss: 0.2228 - val_accuracy: 0.9393\n",
            "Epoch 368/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0276 - accuracy: 0.9985 - val_loss: 0.2215 - val_accuracy: 0.9393\n",
            "Epoch 369/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0232 - accuracy: 0.9985 - val_loss: 0.2201 - val_accuracy: 0.9393\n",
            "Epoch 370/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0240 - accuracy: 0.9990 - val_loss: 0.2189 - val_accuracy: 0.9393\n",
            "Epoch 371/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0251 - accuracy: 0.9980 - val_loss: 0.2177 - val_accuracy: 0.9417\n",
            "Epoch 372/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0283 - accuracy: 0.9980 - val_loss: 0.2166 - val_accuracy: 0.9417\n",
            "Epoch 373/400\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0244 - accuracy: 0.9990 - val_loss: 0.2155 - val_accuracy: 0.9417\n",
            "Epoch 374/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0270 - accuracy: 0.9969 - val_loss: 0.2143 - val_accuracy: 0.9417\n",
            "Epoch 375/400\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0265 - accuracy: 0.9985 - val_loss: 0.2132 - val_accuracy: 0.9417\n",
            "Epoch 376/400\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0247 - accuracy: 0.9995 - val_loss: 0.2122 - val_accuracy: 0.9417\n",
            "Epoch 377/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0254 - accuracy: 0.9985 - val_loss: 0.2112 - val_accuracy: 0.9417\n",
            "Epoch 378/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0247 - accuracy: 0.9985 - val_loss: 0.2101 - val_accuracy: 0.9417\n",
            "Epoch 379/400\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0292 - accuracy: 0.9974 - val_loss: 0.2091 - val_accuracy: 0.9405\n",
            "Epoch 380/400\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0249 - accuracy: 0.9974 - val_loss: 0.2081 - val_accuracy: 0.9405\n",
            "Epoch 381/400\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9405\n",
            "Epoch 382/400\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.0246 - accuracy: 0.9990 - val_loss: 0.2064 - val_accuracy: 0.9417\n",
            "Epoch 383/400\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.0256 - accuracy: 0.9990 - val_loss: 0.2055 - val_accuracy: 0.9429\n",
            "Epoch 384/400\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0242 - accuracy: 0.9980 - val_loss: 0.2047 - val_accuracy: 0.9429\n",
            "Epoch 385/400\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0234 - accuracy: 0.9995 - val_loss: 0.2038 - val_accuracy: 0.9440\n",
            "Epoch 386/400\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0232 - accuracy: 0.9995 - val_loss: 0.2030 - val_accuracy: 0.9440\n",
            "Epoch 387/400\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0258 - accuracy: 0.9980 - val_loss: 0.2021 - val_accuracy: 0.9452\n",
            "Epoch 388/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0257 - accuracy: 0.9980 - val_loss: 0.2014 - val_accuracy: 0.9452\n",
            "Epoch 389/400\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0266 - accuracy: 0.9990 - val_loss: 0.2008 - val_accuracy: 0.9452\n",
            "Epoch 390/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0238 - accuracy: 0.9980 - val_loss: 0.2001 - val_accuracy: 0.9452\n",
            "Epoch 391/400\n",
            "1/1 [==============================] - 0s 498ms/step - loss: 0.0255 - accuracy: 0.9985 - val_loss: 0.1994 - val_accuracy: 0.9452\n",
            "Epoch 392/400\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0233 - accuracy: 0.9990 - val_loss: 0.1987 - val_accuracy: 0.9452\n",
            "Epoch 393/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0236 - accuracy: 0.9980 - val_loss: 0.1980 - val_accuracy: 0.9452\n",
            "Epoch 394/400\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0250 - accuracy: 0.9974 - val_loss: 0.1972 - val_accuracy: 0.9452\n",
            "Epoch 395/400\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.0271 - accuracy: 0.9990 - val_loss: 0.1964 - val_accuracy: 0.9452\n",
            "Epoch 396/400\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0235 - accuracy: 0.9985 - val_loss: 0.1955 - val_accuracy: 0.9464\n",
            "Epoch 397/400\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0310 - accuracy: 0.9980 - val_loss: 0.1946 - val_accuracy: 0.9476\n",
            "Epoch 398/400\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0246 - accuracy: 0.9980 - val_loss: 0.1938 - val_accuracy: 0.9476\n",
            "Epoch 399/400\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.0255 - accuracy: 0.9985 - val_loss: 0.1930 - val_accuracy: 0.9488\n",
            "Epoch 400/400\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0249 - accuracy: 0.9990 - val_loss: 0.1923 - val_accuracy: 0.9488\n",
            "Epoch 1/500\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0260 - accuracy: 0.9990 - val_loss: 0.1952 - val_accuracy: 0.9464\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0232 - accuracy: 0.9980 - val_loss: 0.1927 - val_accuracy: 0.9464\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0259 - accuracy: 0.9990 - val_loss: 0.1928 - val_accuracy: 0.9464\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0268 - accuracy: 0.9980 - val_loss: 0.1929 - val_accuracy: 0.9488\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0250 - accuracy: 0.9980 - val_loss: 0.1892 - val_accuracy: 0.9512\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0266 - accuracy: 0.9980 - val_loss: 0.1883 - val_accuracy: 0.9512\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.1879 - val_accuracy: 0.9524\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0264 - accuracy: 0.9995 - val_loss: 0.1876 - val_accuracy: 0.9524\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0241 - accuracy: 0.9980 - val_loss: 0.1863 - val_accuracy: 0.9512\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0297 - accuracy: 0.9964 - val_loss: 0.1850 - val_accuracy: 0.9524\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0263 - accuracy: 0.9974 - val_loss: 0.1841 - val_accuracy: 0.9524\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0259 - accuracy: 0.9964 - val_loss: 0.1833 - val_accuracy: 0.9524\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0267 - accuracy: 0.9969 - val_loss: 0.1819 - val_accuracy: 0.9512\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 495ms/step - loss: 0.0286 - accuracy: 0.9974 - val_loss: 0.1801 - val_accuracy: 0.9512\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0305 - accuracy: 0.9964 - val_loss: 0.1779 - val_accuracy: 0.9500\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.0225 - accuracy: 0.9990 - val_loss: 0.1763 - val_accuracy: 0.9500\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0242 - accuracy: 0.9995 - val_loss: 0.1754 - val_accuracy: 0.9500\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0260 - accuracy: 0.9969 - val_loss: 0.1749 - val_accuracy: 0.9500\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0274 - accuracy: 0.9985 - val_loss: 0.1759 - val_accuracy: 0.9500\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.0281 - accuracy: 0.9980 - val_loss: 0.1773 - val_accuracy: 0.9500\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0282 - accuracy: 0.9969 - val_loss: 0.1795 - val_accuracy: 0.9500\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.0218 - accuracy: 0.9985 - val_loss: 0.1803 - val_accuracy: 0.9500\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9512\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0235 - accuracy: 0.9995 - val_loss: 0.1816 - val_accuracy: 0.9512\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0221 - accuracy: 0.9995 - val_loss: 0.1824 - val_accuracy: 0.9500\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0296 - accuracy: 0.9954 - val_loss: 0.1830 - val_accuracy: 0.9500\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0243 - accuracy: 0.9980 - val_loss: 0.1836 - val_accuracy: 0.9500\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0222 - accuracy: 0.9985 - val_loss: 0.1843 - val_accuracy: 0.9488\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0231 - accuracy: 0.9985 - val_loss: 0.1848 - val_accuracy: 0.9488\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0229 - accuracy: 0.9990 - val_loss: 0.1850 - val_accuracy: 0.9488\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0239 - accuracy: 0.9995 - val_loss: 0.1849 - val_accuracy: 0.9488\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0231 - accuracy: 0.9990 - val_loss: 0.1848 - val_accuracy: 0.9512\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 1s 500ms/step - loss: 0.0253 - accuracy: 0.9974 - val_loss: 0.1846 - val_accuracy: 0.9512\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.0242 - accuracy: 0.9985 - val_loss: 0.1843 - val_accuracy: 0.9512\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0263 - accuracy: 0.9980 - val_loss: 0.1841 - val_accuracy: 0.9512\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0236 - accuracy: 0.9990 - val_loss: 0.1837 - val_accuracy: 0.9512\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0237 - accuracy: 0.9985 - val_loss: 0.1832 - val_accuracy: 0.9512\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 1s 503ms/step - loss: 0.0234 - accuracy: 0.9990 - val_loss: 0.1827 - val_accuracy: 0.9524\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0234 - accuracy: 0.9990 - val_loss: 0.1820 - val_accuracy: 0.9524\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0241 - accuracy: 0.9985 - val_loss: 0.1815 - val_accuracy: 0.9524\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0264 - accuracy: 0.9959 - val_loss: 0.1810 - val_accuracy: 0.9524\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 497ms/step - loss: 0.0226 - accuracy: 0.9990 - val_loss: 0.1805 - val_accuracy: 0.9524\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0273 - accuracy: 0.9964 - val_loss: 0.1800 - val_accuracy: 0.9524\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0234 - accuracy: 0.9985 - val_loss: 0.1796 - val_accuracy: 0.9524\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0232 - accuracy: 0.9980 - val_loss: 0.1791 - val_accuracy: 0.9524\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0224 - accuracy: 0.9990 - val_loss: 0.1787 - val_accuracy: 0.9524\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9524\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0225 - accuracy: 0.9974 - val_loss: 0.1777 - val_accuracy: 0.9524\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0226 - accuracy: 0.9990 - val_loss: 0.1772 - val_accuracy: 0.9524\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0262 - accuracy: 0.9974 - val_loss: 0.1768 - val_accuracy: 0.9524\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0240 - accuracy: 0.9990 - val_loss: 0.1764 - val_accuracy: 0.9524\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0278 - accuracy: 0.9974 - val_loss: 0.1760 - val_accuracy: 0.9524\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0256 - accuracy: 0.9985 - val_loss: 0.1756 - val_accuracy: 0.9524\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0231 - accuracy: 0.9990 - val_loss: 0.1752 - val_accuracy: 0.9524\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0239 - accuracy: 0.9985 - val_loss: 0.1749 - val_accuracy: 0.9536\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0236 - accuracy: 0.9990 - val_loss: 0.1746 - val_accuracy: 0.9548\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0232 - accuracy: 0.9980 - val_loss: 0.1743 - val_accuracy: 0.9548\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0255 - accuracy: 0.9985 - val_loss: 0.1739 - val_accuracy: 0.9548\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0227 - accuracy: 0.9995 - val_loss: 0.1736 - val_accuracy: 0.9548\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0239 - accuracy: 0.9974 - val_loss: 0.1732 - val_accuracy: 0.9560\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 495ms/step - loss: 0.0213 - accuracy: 0.9985 - val_loss: 0.1729 - val_accuracy: 0.9560\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0251 - accuracy: 0.9980 - val_loss: 0.1725 - val_accuracy: 0.9560\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0259 - accuracy: 0.9980 - val_loss: 0.1721 - val_accuracy: 0.9560\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0231 - accuracy: 0.9985 - val_loss: 0.1717 - val_accuracy: 0.9571\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0219 - accuracy: 0.9985 - val_loss: 0.1713 - val_accuracy: 0.9571\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0229 - accuracy: 0.9985 - val_loss: 0.1709 - val_accuracy: 0.9571\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0224 - accuracy: 0.9995 - val_loss: 0.1706 - val_accuracy: 0.9571\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0217 - accuracy: 0.9990 - val_loss: 0.1702 - val_accuracy: 0.9571\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0232 - accuracy: 0.9990 - val_loss: 0.1699 - val_accuracy: 0.9571\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0242 - accuracy: 0.9985 - val_loss: 0.1697 - val_accuracy: 0.9571\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0247 - accuracy: 0.9980 - val_loss: 0.1694 - val_accuracy: 0.9571\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0220 - accuracy: 0.9990 - val_loss: 0.1691 - val_accuracy: 0.9571\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0239 - accuracy: 0.9985 - val_loss: 0.1689 - val_accuracy: 0.9583\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0241 - accuracy: 0.9990 - val_loss: 0.1687 - val_accuracy: 0.9595\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0232 - accuracy: 0.9980 - val_loss: 0.1686 - val_accuracy: 0.9595\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0226 - accuracy: 0.9995 - val_loss: 0.1684 - val_accuracy: 0.9595\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0230 - accuracy: 0.9990 - val_loss: 0.1682 - val_accuracy: 0.9595\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0239 - accuracy: 0.9985 - val_loss: 0.1680 - val_accuracy: 0.9595\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0236 - accuracy: 0.9974 - val_loss: 0.1678 - val_accuracy: 0.9595\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0244 - accuracy: 0.9980 - val_loss: 0.1675 - val_accuracy: 0.9595\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0261 - accuracy: 0.9980 - val_loss: 0.1673 - val_accuracy: 0.9595\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0232 - accuracy: 0.9985 - val_loss: 0.1671 - val_accuracy: 0.9595\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0232 - accuracy: 0.9974 - val_loss: 0.1669 - val_accuracy: 0.9595\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0269 - accuracy: 0.9985 - val_loss: 0.1668 - val_accuracy: 0.9595\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9595\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0219 - accuracy: 0.9985 - val_loss: 0.1666 - val_accuracy: 0.9595\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.0263 - accuracy: 0.9985 - val_loss: 0.1665 - val_accuracy: 0.9595\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0246 - accuracy: 0.9980 - val_loss: 0.1664 - val_accuracy: 0.9595\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0206 - accuracy: 0.9990 - val_loss: 0.1663 - val_accuracy: 0.9595\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0247 - accuracy: 0.9985 - val_loss: 0.1662 - val_accuracy: 0.9595\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0214 - accuracy: 0.9995 - val_loss: 0.1662 - val_accuracy: 0.9595\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.0230 - accuracy: 0.9985 - val_loss: 0.1660 - val_accuracy: 0.9595\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 498ms/step - loss: 0.0226 - accuracy: 0.9990 - val_loss: 0.1659 - val_accuracy: 0.9595\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9583\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0194 - accuracy: 0.9995 - val_loss: 0.1656 - val_accuracy: 0.9595\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.1655 - val_accuracy: 0.9595\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0187 - accuracy: 0.9995 - val_loss: 0.1654 - val_accuracy: 0.9595\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0215 - accuracy: 0.9990 - val_loss: 0.1652 - val_accuracy: 0.9595\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0213 - accuracy: 0.9990 - val_loss: 0.1651 - val_accuracy: 0.9595\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0258 - accuracy: 0.9980 - val_loss: 0.1649 - val_accuracy: 0.9595\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0219 - accuracy: 0.9985 - val_loss: 0.1648 - val_accuracy: 0.9595\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0208 - accuracy: 0.9985 - val_loss: 0.1647 - val_accuracy: 0.9595\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0257 - accuracy: 0.9990 - val_loss: 0.1646 - val_accuracy: 0.9595\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0246 - accuracy: 0.9985 - val_loss: 0.1645 - val_accuracy: 0.9595\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0250 - accuracy: 0.9980 - val_loss: 0.1644 - val_accuracy: 0.9595\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0224 - accuracy: 0.9995 - val_loss: 0.1643 - val_accuracy: 0.9595\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0217 - accuracy: 0.9995 - val_loss: 0.1642 - val_accuracy: 0.9595\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0212 - accuracy: 0.9990 - val_loss: 0.1641 - val_accuracy: 0.9607\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0233 - accuracy: 0.9985 - val_loss: 0.1639 - val_accuracy: 0.9607\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0214 - accuracy: 0.9985 - val_loss: 0.1638 - val_accuracy: 0.9607\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0200 - accuracy: 0.9995 - val_loss: 0.1637 - val_accuracy: 0.9607\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 493ms/step - loss: 0.0224 - accuracy: 0.9985 - val_loss: 0.1637 - val_accuracy: 0.9607\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0214 - accuracy: 0.9985 - val_loss: 0.1636 - val_accuracy: 0.9607\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9607\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0266 - accuracy: 0.9990 - val_loss: 0.1635 - val_accuracy: 0.9607\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0244 - accuracy: 0.9980 - val_loss: 0.1634 - val_accuracy: 0.9607\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0244 - accuracy: 0.9969 - val_loss: 0.1634 - val_accuracy: 0.9607\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0195 - accuracy: 0.9985 - val_loss: 0.1634 - val_accuracy: 0.9607\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9607\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0251 - accuracy: 0.9980 - val_loss: 0.1634 - val_accuracy: 0.9607\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0196 - accuracy: 0.9990 - val_loss: 0.1635 - val_accuracy: 0.9607\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0243 - accuracy: 0.9990 - val_loss: 0.1635 - val_accuracy: 0.9607\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0246 - accuracy: 0.9974 - val_loss: 0.1635 - val_accuracy: 0.9607\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0213 - accuracy: 0.9990 - val_loss: 0.1635 - val_accuracy: 0.9607\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0195 - accuracy: 0.9995 - val_loss: 0.1635 - val_accuracy: 0.9607\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9607\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0228 - accuracy: 0.9990 - val_loss: 0.1635 - val_accuracy: 0.9607\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0227 - accuracy: 0.9985 - val_loss: 0.1635 - val_accuracy: 0.9607\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0220 - accuracy: 0.9985 - val_loss: 0.1635 - val_accuracy: 0.9607\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0224 - accuracy: 0.9990 - val_loss: 0.1636 - val_accuracy: 0.9607\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0254 - accuracy: 0.9985 - val_loss: 0.1636 - val_accuracy: 0.9607\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0206 - accuracy: 0.9995 - val_loss: 0.1636 - val_accuracy: 0.9607\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0238 - accuracy: 0.9969 - val_loss: 0.1637 - val_accuracy: 0.9607\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0237 - accuracy: 0.9985 - val_loss: 0.1637 - val_accuracy: 0.9607\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0234 - accuracy: 0.9985 - val_loss: 0.1637 - val_accuracy: 0.9607\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0223 - accuracy: 0.9985 - val_loss: 0.1637 - val_accuracy: 0.9619\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0205 - accuracy: 0.9995 - val_loss: 0.1637 - val_accuracy: 0.9619\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0225 - accuracy: 0.9990 - val_loss: 0.1637 - val_accuracy: 0.9619\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9619\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0241 - accuracy: 0.9980 - val_loss: 0.1637 - val_accuracy: 0.9619\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0226 - accuracy: 0.9995 - val_loss: 0.1638 - val_accuracy: 0.9619\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0228 - accuracy: 0.9974 - val_loss: 0.1638 - val_accuracy: 0.9619\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0221 - accuracy: 0.9995 - val_loss: 0.1638 - val_accuracy: 0.9619\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0248 - accuracy: 0.9980 - val_loss: 0.1638 - val_accuracy: 0.9619\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.0189 - accuracy: 0.9990 - val_loss: 0.1638 - val_accuracy: 0.9619\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0226 - accuracy: 0.9990 - val_loss: 0.1639 - val_accuracy: 0.9619\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0209 - accuracy: 0.9990 - val_loss: 0.1640 - val_accuracy: 0.9619\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.0256 - accuracy: 0.9964 - val_loss: 0.1640 - val_accuracy: 0.9619\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0202 - accuracy: 0.9995 - val_loss: 0.1641 - val_accuracy: 0.9619\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0198 - accuracy: 0.9985 - val_loss: 0.1642 - val_accuracy: 0.9619\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.0213 - accuracy: 0.9980 - val_loss: 0.1642 - val_accuracy: 0.9619\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0215 - accuracy: 0.9995 - val_loss: 0.1643 - val_accuracy: 0.9619\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0214 - accuracy: 0.9995 - val_loss: 0.1643 - val_accuracy: 0.9619\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0224 - accuracy: 0.9995 - val_loss: 0.1643 - val_accuracy: 0.9619\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0208 - accuracy: 0.9995 - val_loss: 0.1642 - val_accuracy: 0.9619\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0216 - accuracy: 0.9980 - val_loss: 0.1642 - val_accuracy: 0.9619\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.0211 - accuracy: 0.9990 - val_loss: 0.1642 - val_accuracy: 0.9619\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0230 - accuracy: 0.9985 - val_loss: 0.1641 - val_accuracy: 0.9619\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0219 - accuracy: 0.9990 - val_loss: 0.1640 - val_accuracy: 0.9619\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0260 - accuracy: 0.9985 - val_loss: 0.1639 - val_accuracy: 0.9619\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0197 - accuracy: 0.9995 - val_loss: 0.1638 - val_accuracy: 0.9619\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0225 - accuracy: 0.9980 - val_loss: 0.1637 - val_accuracy: 0.9619\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0227 - accuracy: 0.9969 - val_loss: 0.1637 - val_accuracy: 0.9619\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0239 - accuracy: 0.9980 - val_loss: 0.1637 - val_accuracy: 0.9607\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0201 - accuracy: 0.9990 - val_loss: 0.1636 - val_accuracy: 0.9607\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0250 - accuracy: 0.9974 - val_loss: 0.1636 - val_accuracy: 0.9619\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0224 - accuracy: 0.9985 - val_loss: 0.1636 - val_accuracy: 0.9619\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0213 - accuracy: 0.9980 - val_loss: 0.1636 - val_accuracy: 0.9619\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.0238 - accuracy: 0.9990 - val_loss: 0.1636 - val_accuracy: 0.9619\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0221 - accuracy: 0.9990 - val_loss: 0.1636 - val_accuracy: 0.9619\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0217 - accuracy: 0.9990 - val_loss: 0.1637 - val_accuracy: 0.9619\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0233 - accuracy: 0.9959 - val_loss: 0.1638 - val_accuracy: 0.9619\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9619\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0226 - accuracy: 0.9990 - val_loss: 0.1639 - val_accuracy: 0.9619\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0231 - accuracy: 0.9990 - val_loss: 0.1639 - val_accuracy: 0.9619\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0230 - accuracy: 0.9974 - val_loss: 0.1640 - val_accuracy: 0.9619\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0253 - accuracy: 0.9974 - val_loss: 0.1641 - val_accuracy: 0.9619\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0203 - accuracy: 0.9985 - val_loss: 0.1641 - val_accuracy: 0.9619\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0244 - accuracy: 0.9974 - val_loss: 0.1642 - val_accuracy: 0.9619\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0207 - accuracy: 0.9995 - val_loss: 0.1642 - val_accuracy: 0.9619\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0214 - accuracy: 0.9990 - val_loss: 0.1643 - val_accuracy: 0.9619\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0222 - accuracy: 0.9985 - val_loss: 0.1643 - val_accuracy: 0.9619\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0196 - accuracy: 0.9990 - val_loss: 0.1644 - val_accuracy: 0.9619\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0197 - accuracy: 0.9995 - val_loss: 0.1644 - val_accuracy: 0.9607\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0208 - accuracy: 0.9990 - val_loss: 0.1645 - val_accuracy: 0.9619\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0192 - accuracy: 0.9995 - val_loss: 0.1645 - val_accuracy: 0.9619\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0218 - accuracy: 0.9985 - val_loss: 0.1646 - val_accuracy: 0.9619\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0217 - accuracy: 0.9990 - val_loss: 0.1646 - val_accuracy: 0.9619\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 495ms/step - loss: 0.0184 - accuracy: 0.9990 - val_loss: 0.1647 - val_accuracy: 0.9619\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0231 - accuracy: 0.9990 - val_loss: 0.1647 - val_accuracy: 0.9619\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0219 - accuracy: 0.9990 - val_loss: 0.1647 - val_accuracy: 0.9619\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0206 - accuracy: 0.9990 - val_loss: 0.1647 - val_accuracy: 0.9619\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 497ms/step - loss: 0.0227 - accuracy: 0.9995 - val_loss: 0.1647 - val_accuracy: 0.9619\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0207 - accuracy: 0.9995 - val_loss: 0.1647 - val_accuracy: 0.9619\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.1646 - val_accuracy: 0.9619\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.0209 - accuracy: 0.9995 - val_loss: 0.1647 - val_accuracy: 0.9619\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0206 - accuracy: 0.9990 - val_loss: 0.1647 - val_accuracy: 0.9619\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0232 - accuracy: 0.9990 - val_loss: 0.1647 - val_accuracy: 0.9619\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0231 - accuracy: 0.9974 - val_loss: 0.1647 - val_accuracy: 0.9619\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.0239 - accuracy: 0.9985 - val_loss: 0.1647 - val_accuracy: 0.9619\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0216 - accuracy: 0.9990 - val_loss: 0.1647 - val_accuracy: 0.9619\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0244 - accuracy: 0.9974 - val_loss: 0.1647 - val_accuracy: 0.9619\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0210 - accuracy: 0.9990 - val_loss: 0.1648 - val_accuracy: 0.9619\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0216 - accuracy: 0.9995 - val_loss: 0.1648 - val_accuracy: 0.9619\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0222 - accuracy: 0.9990 - val_loss: 0.1648 - val_accuracy: 0.9619\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0234 - accuracy: 0.9985 - val_loss: 0.1649 - val_accuracy: 0.9619\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0221 - accuracy: 0.9990 - val_loss: 0.1649 - val_accuracy: 0.9619\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0253 - accuracy: 0.9964 - val_loss: 0.1650 - val_accuracy: 0.9619\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.0237 - accuracy: 0.9980 - val_loss: 0.1650 - val_accuracy: 0.9619\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0273 - accuracy: 0.9954 - val_loss: 0.1651 - val_accuracy: 0.9619\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0215 - accuracy: 0.9985 - val_loss: 0.1651 - val_accuracy: 0.9619\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.0193 - accuracy: 0.9990 - val_loss: 0.1652 - val_accuracy: 0.9619\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0198 - accuracy: 0.9985 - val_loss: 0.1653 - val_accuracy: 0.9619\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0217 - accuracy: 0.9990 - val_loss: 0.1654 - val_accuracy: 0.9619\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0254 - accuracy: 0.9985 - val_loss: 0.1654 - val_accuracy: 0.9619\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0214 - accuracy: 0.9995 - val_loss: 0.1655 - val_accuracy: 0.9619\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0218 - accuracy: 0.9995 - val_loss: 0.1656 - val_accuracy: 0.9619\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0242 - accuracy: 0.9985 - val_loss: 0.1656 - val_accuracy: 0.9619\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0198 - accuracy: 0.9990 - val_loss: 0.1657 - val_accuracy: 0.9619\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0235 - accuracy: 0.9985 - val_loss: 0.1658 - val_accuracy: 0.9619\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.0200 - accuracy: 0.9985 - val_loss: 0.1659 - val_accuracy: 0.9619\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0262 - accuracy: 0.9969 - val_loss: 0.1660 - val_accuracy: 0.9619\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0226 - accuracy: 0.9985 - val_loss: 0.1660 - val_accuracy: 0.9619\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0201 - accuracy: 0.9980 - val_loss: 0.1661 - val_accuracy: 0.9619\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0218 - accuracy: 0.9990 - val_loss: 0.1662 - val_accuracy: 0.9619\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.0223 - accuracy: 0.9990 - val_loss: 0.1663 - val_accuracy: 0.9619\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0219 - accuracy: 0.9985 - val_loss: 0.1664 - val_accuracy: 0.9619\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0213 - accuracy: 0.9990 - val_loss: 0.1664 - val_accuracy: 0.9619\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0207 - accuracy: 0.9995 - val_loss: 0.1664 - val_accuracy: 0.9619\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9619\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0191 - accuracy: 0.9995 - val_loss: 0.1665 - val_accuracy: 0.9619\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0245 - accuracy: 0.9969 - val_loss: 0.1664 - val_accuracy: 0.9619\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0235 - accuracy: 0.9985 - val_loss: 0.1664 - val_accuracy: 0.9619\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0245 - accuracy: 0.9985 - val_loss: 0.1664 - val_accuracy: 0.9619\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0220 - accuracy: 0.9990 - val_loss: 0.1665 - val_accuracy: 0.9619\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.0246 - accuracy: 0.9980 - val_loss: 0.1664 - val_accuracy: 0.9619\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0205 - accuracy: 0.9985 - val_loss: 0.1664 - val_accuracy: 0.9619\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0211 - accuracy: 0.9985 - val_loss: 0.1664 - val_accuracy: 0.9619\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.0213 - accuracy: 0.9995 - val_loss: 0.1664 - val_accuracy: 0.9619\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0196 - accuracy: 0.9990 - val_loss: 0.1664 - val_accuracy: 0.9619\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0209 - accuracy: 0.9985 - val_loss: 0.1664 - val_accuracy: 0.9619\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0258 - accuracy: 0.9959 - val_loss: 0.1665 - val_accuracy: 0.9619\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0214 - accuracy: 0.9990 - val_loss: 0.1665 - val_accuracy: 0.9619\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0238 - accuracy: 0.9974 - val_loss: 0.1665 - val_accuracy: 0.9619\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.0218 - accuracy: 0.9990 - val_loss: 0.1666 - val_accuracy: 0.9619\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0200 - accuracy: 0.9995 - val_loss: 0.1666 - val_accuracy: 0.9619\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0194 - accuracy: 0.9995 - val_loss: 0.1666 - val_accuracy: 0.9619\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9619\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0243 - accuracy: 0.9974 - val_loss: 0.1667 - val_accuracy: 0.9619\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0240 - accuracy: 0.9995 - val_loss: 0.1668 - val_accuracy: 0.9619\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0209 - accuracy: 0.9985 - val_loss: 0.1669 - val_accuracy: 0.9619\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 494ms/step - loss: 0.0203 - accuracy: 0.9985 - val_loss: 0.1669 - val_accuracy: 0.9619\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9619\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0241 - accuracy: 0.9969 - val_loss: 0.1670 - val_accuracy: 0.9619\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0198 - accuracy: 0.9985 - val_loss: 0.1670 - val_accuracy: 0.9619\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 1s 506ms/step - loss: 0.0204 - accuracy: 0.9985 - val_loss: 0.1671 - val_accuracy: 0.9619\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.0228 - accuracy: 0.9969 - val_loss: 0.1671 - val_accuracy: 0.9619\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.0205 - accuracy: 0.9985 - val_loss: 0.1672 - val_accuracy: 0.9619\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0222 - accuracy: 0.9995 - val_loss: 0.1672 - val_accuracy: 0.9619\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 493ms/step - loss: 0.0235 - accuracy: 0.9985 - val_loss: 0.1673 - val_accuracy: 0.9619\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0199 - accuracy: 0.9980 - val_loss: 0.1673 - val_accuracy: 0.9619\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0203 - accuracy: 0.9985 - val_loss: 0.1673 - val_accuracy: 0.9619\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9619\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0214 - accuracy: 0.9990 - val_loss: 0.1674 - val_accuracy: 0.9619\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0216 - accuracy: 0.9985 - val_loss: 0.1675 - val_accuracy: 0.9619\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0234 - accuracy: 0.9985 - val_loss: 0.1676 - val_accuracy: 0.9619\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0203 - accuracy: 0.9985 - val_loss: 0.1677 - val_accuracy: 0.9619\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0207 - accuracy: 0.9990 - val_loss: 0.1678 - val_accuracy: 0.9619\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0236 - accuracy: 0.9985 - val_loss: 0.1679 - val_accuracy: 0.9619\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.0214 - accuracy: 0.9995 - val_loss: 0.1680 - val_accuracy: 0.9619\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0240 - accuracy: 0.9985 - val_loss: 0.1681 - val_accuracy: 0.9619\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0226 - accuracy: 0.9985 - val_loss: 0.1682 - val_accuracy: 0.9619\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0208 - accuracy: 0.9990 - val_loss: 0.1684 - val_accuracy: 0.9619\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0188 - accuracy: 0.9990 - val_loss: 0.1685 - val_accuracy: 0.9619\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0216 - accuracy: 0.9980 - val_loss: 0.1687 - val_accuracy: 0.9619\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.0214 - accuracy: 0.9990 - val_loss: 0.1688 - val_accuracy: 0.9619\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0203 - accuracy: 0.9995 - val_loss: 0.1690 - val_accuracy: 0.9619\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0205 - accuracy: 0.9995 - val_loss: 0.1690 - val_accuracy: 0.9619\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0209 - accuracy: 0.9990 - val_loss: 0.1691 - val_accuracy: 0.9619\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0224 - accuracy: 0.9990 - val_loss: 0.1692 - val_accuracy: 0.9619\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0239 - accuracy: 0.9980 - val_loss: 0.1693 - val_accuracy: 0.9619\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0213 - accuracy: 0.9980 - val_loss: 0.1694 - val_accuracy: 0.9619\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0205 - accuracy: 0.9990 - val_loss: 0.1694 - val_accuracy: 0.9619\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.0203 - accuracy: 0.9990 - val_loss: 0.1694 - val_accuracy: 0.9619\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0195 - accuracy: 0.9990 - val_loss: 0.1694 - val_accuracy: 0.9619\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0208 - accuracy: 0.9995 - val_loss: 0.1694 - val_accuracy: 0.9619\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.0207 - accuracy: 0.9990 - val_loss: 0.1694 - val_accuracy: 0.9619\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0190 - accuracy: 0.9995 - val_loss: 0.1693 - val_accuracy: 0.9619\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9619\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0245 - accuracy: 0.9980 - val_loss: 0.1693 - val_accuracy: 0.9619\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0216 - accuracy: 0.9985 - val_loss: 0.1693 - val_accuracy: 0.9631\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0220 - accuracy: 0.9974 - val_loss: 0.1693 - val_accuracy: 0.9631\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0205 - accuracy: 0.9995 - val_loss: 0.1693 - val_accuracy: 0.9631\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.0230 - accuracy: 0.9985 - val_loss: 0.1693 - val_accuracy: 0.9631\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0208 - accuracy: 0.9985 - val_loss: 0.1693 - val_accuracy: 0.9631\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0197 - accuracy: 0.9995 - val_loss: 0.1694 - val_accuracy: 0.9631\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0208 - accuracy: 0.9995 - val_loss: 0.1695 - val_accuracy: 0.9631\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9631\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0207 - accuracy: 0.9990 - val_loss: 0.1697 - val_accuracy: 0.9631\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 499ms/step - loss: 0.0194 - accuracy: 0.9990 - val_loss: 0.1697 - val_accuracy: 0.9631\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9619\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0223 - accuracy: 0.9990 - val_loss: 0.1698 - val_accuracy: 0.9631\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0201 - accuracy: 0.9980 - val_loss: 0.1699 - val_accuracy: 0.9631\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0199 - accuracy: 0.9980 - val_loss: 0.1699 - val_accuracy: 0.9631\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0223 - accuracy: 0.9974 - val_loss: 0.1699 - val_accuracy: 0.9631\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.9631\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0251 - accuracy: 0.9974 - val_loss: 0.1701 - val_accuracy: 0.9631\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0204 - accuracy: 0.9990 - val_loss: 0.1701 - val_accuracy: 0.9631\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9631\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0191 - accuracy: 0.9985 - val_loss: 0.1703 - val_accuracy: 0.9631\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0226 - accuracy: 0.9980 - val_loss: 0.1703 - val_accuracy: 0.9631\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0231 - accuracy: 0.9990 - val_loss: 0.1703 - val_accuracy: 0.9631\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0188 - accuracy: 0.9995 - val_loss: 0.1704 - val_accuracy: 0.9631\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0190 - accuracy: 0.9990 - val_loss: 0.1704 - val_accuracy: 0.9619\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.0197 - accuracy: 0.9995 - val_loss: 0.1704 - val_accuracy: 0.9619\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.0216 - accuracy: 0.9985 - val_loss: 0.1704 - val_accuracy: 0.9619\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0202 - accuracy: 0.9990 - val_loss: 0.1703 - val_accuracy: 0.9619\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0213 - accuracy: 0.9974 - val_loss: 0.1702 - val_accuracy: 0.9619\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.0208 - accuracy: 0.9990 - val_loss: 0.1701 - val_accuracy: 0.9619\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0176 - accuracy: 0.9995 - val_loss: 0.1700 - val_accuracy: 0.9631\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0213 - accuracy: 0.9995 - val_loss: 0.1699 - val_accuracy: 0.9631\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0211 - accuracy: 0.9980 - val_loss: 0.1698 - val_accuracy: 0.9631\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.0180 - accuracy: 0.9995 - val_loss: 0.1697 - val_accuracy: 0.9631\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0250 - accuracy: 0.9964 - val_loss: 0.1697 - val_accuracy: 0.9631\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.0238 - accuracy: 0.9964 - val_loss: 0.1697 - val_accuracy: 0.9631\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0223 - accuracy: 0.9980 - val_loss: 0.1697 - val_accuracy: 0.9631\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9631\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0216 - accuracy: 0.9985 - val_loss: 0.1698 - val_accuracy: 0.9631\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0220 - accuracy: 0.9980 - val_loss: 0.1699 - val_accuracy: 0.9631\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9631\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 1s 595ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.9631\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 495ms/step - loss: 0.0214 - accuracy: 0.9974 - val_loss: 0.1700 - val_accuracy: 0.9631\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0212 - accuracy: 0.9990 - val_loss: 0.1700 - val_accuracy: 0.9631\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0260 - accuracy: 0.9985 - val_loss: 0.1700 - val_accuracy: 0.9631\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0306 - accuracy: 0.9959 - val_loss: 0.1701 - val_accuracy: 0.9631\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0206 - accuracy: 0.9990 - val_loss: 0.1702 - val_accuracy: 0.9631\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0196 - accuracy: 0.9985 - val_loss: 0.1702 - val_accuracy: 0.9631\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0221 - accuracy: 0.9990 - val_loss: 0.1703 - val_accuracy: 0.9631\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0174 - accuracy: 0.9995 - val_loss: 0.1703 - val_accuracy: 0.9631\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0207 - accuracy: 0.9995 - val_loss: 0.1703 - val_accuracy: 0.9631\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0217 - accuracy: 0.9990 - val_loss: 0.1703 - val_accuracy: 0.9631\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0211 - accuracy: 0.9995 - val_loss: 0.1704 - val_accuracy: 0.9631\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0223 - accuracy: 0.9995 - val_loss: 0.1704 - val_accuracy: 0.9631\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0212 - accuracy: 0.9985 - val_loss: 0.1704 - val_accuracy: 0.9631\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0197 - accuracy: 0.9980 - val_loss: 0.1704 - val_accuracy: 0.9631\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0187 - accuracy: 0.9995 - val_loss: 0.1705 - val_accuracy: 0.9631\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0226 - accuracy: 0.9990 - val_loss: 0.1706 - val_accuracy: 0.9631\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0212 - accuracy: 0.9990 - val_loss: 0.1706 - val_accuracy: 0.9631\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0207 - accuracy: 0.9990 - val_loss: 0.1707 - val_accuracy: 0.9631\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9631\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9631\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.0245 - accuracy: 0.9980 - val_loss: 0.1708 - val_accuracy: 0.9631\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0217 - accuracy: 0.9985 - val_loss: 0.1708 - val_accuracy: 0.9631\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0201 - accuracy: 0.9985 - val_loss: 0.1708 - val_accuracy: 0.9631\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0213 - accuracy: 0.9980 - val_loss: 0.1708 - val_accuracy: 0.9631\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.0196 - accuracy: 0.9995 - val_loss: 0.1708 - val_accuracy: 0.9631\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.0199 - accuracy: 0.9990 - val_loss: 0.1708 - val_accuracy: 0.9631\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0214 - accuracy: 0.9985 - val_loss: 0.1707 - val_accuracy: 0.9631\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0190 - accuracy: 0.9990 - val_loss: 0.1707 - val_accuracy: 0.9631\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.0222 - accuracy: 0.9990 - val_loss: 0.1707 - val_accuracy: 0.9631\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 1s 508ms/step - loss: 0.0190 - accuracy: 0.9990 - val_loss: 0.1707 - val_accuracy: 0.9631\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 494ms/step - loss: 0.0219 - accuracy: 0.9985 - val_loss: 0.1708 - val_accuracy: 0.9631\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9631\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0217 - accuracy: 0.9985 - val_loss: 0.1709 - val_accuracy: 0.9631\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0187 - accuracy: 0.9990 - val_loss: 0.1709 - val_accuracy: 0.9631\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0198 - accuracy: 0.9990 - val_loss: 0.1710 - val_accuracy: 0.9631\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9619\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0210 - accuracy: 0.9985 - val_loss: 0.1710 - val_accuracy: 0.9619\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0177 - accuracy: 0.9995 - val_loss: 0.1710 - val_accuracy: 0.9619\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0223 - accuracy: 0.9974 - val_loss: 0.1710 - val_accuracy: 0.9619\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0217 - accuracy: 0.9980 - val_loss: 0.1711 - val_accuracy: 0.9619\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0214 - accuracy: 0.9995 - val_loss: 0.1711 - val_accuracy: 0.9619\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0200 - accuracy: 0.9985 - val_loss: 0.1711 - val_accuracy: 0.9619\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0256 - accuracy: 0.9974 - val_loss: 0.1711 - val_accuracy: 0.9619\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0203 - accuracy: 0.9990 - val_loss: 0.1712 - val_accuracy: 0.9619\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.0202 - accuracy: 0.9995 - val_loss: 0.1712 - val_accuracy: 0.9619\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.0240 - accuracy: 0.9985 - val_loss: 0.1712 - val_accuracy: 0.9619\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0209 - accuracy: 0.9990 - val_loss: 0.1713 - val_accuracy: 0.9619\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9619\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0201 - accuracy: 0.9995 - val_loss: 0.1713 - val_accuracy: 0.9619\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9619\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0214 - accuracy: 0.9980 - val_loss: 0.1714 - val_accuracy: 0.9619\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0206 - accuracy: 0.9985 - val_loss: 0.1713 - val_accuracy: 0.9631\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0260 - accuracy: 0.9969 - val_loss: 0.1713 - val_accuracy: 0.9631\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.0238 - accuracy: 0.9980 - val_loss: 0.1713 - val_accuracy: 0.9631\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0216 - accuracy: 0.9985 - val_loss: 0.1714 - val_accuracy: 0.9631\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0192 - accuracy: 0.9995 - val_loss: 0.1714 - val_accuracy: 0.9631\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0209 - accuracy: 0.9980 - val_loss: 0.1714 - val_accuracy: 0.9631\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0236 - accuracy: 0.9974 - val_loss: 0.1714 - val_accuracy: 0.9631\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0211 - accuracy: 0.9985 - val_loss: 0.1714 - val_accuracy: 0.9631\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 500ms/step - loss: 0.0211 - accuracy: 0.9985 - val_loss: 0.1714 - val_accuracy: 0.9631\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0175 - accuracy: 0.9995 - val_loss: 0.1714 - val_accuracy: 0.9631\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0189 - accuracy: 0.9995 - val_loss: 0.1714 - val_accuracy: 0.9631\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0196 - accuracy: 0.9990 - val_loss: 0.1714 - val_accuracy: 0.9631\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0210 - accuracy: 0.9995 - val_loss: 0.1715 - val_accuracy: 0.9619\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0193 - accuracy: 0.9990 - val_loss: 0.1715 - val_accuracy: 0.9619\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.9619\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0220 - accuracy: 0.9980 - val_loss: 0.1715 - val_accuracy: 0.9619\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0225 - accuracy: 0.9990 - val_loss: 0.1716 - val_accuracy: 0.9619\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 498ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9619\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0196 - accuracy: 0.9985 - val_loss: 0.1717 - val_accuracy: 0.9619\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0213 - accuracy: 0.9980 - val_loss: 0.1718 - val_accuracy: 0.9619\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0188 - accuracy: 0.9995 - val_loss: 0.1719 - val_accuracy: 0.9619\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0184 - accuracy: 0.9990 - val_loss: 0.1719 - val_accuracy: 0.9619\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0249 - accuracy: 0.9980 - val_loss: 0.1720 - val_accuracy: 0.9619\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 497ms/step - loss: 0.0226 - accuracy: 0.9964 - val_loss: 0.1720 - val_accuracy: 0.9631\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0204 - accuracy: 0.9995 - val_loss: 0.1720 - val_accuracy: 0.9631\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0200 - accuracy: 0.9995 - val_loss: 0.1721 - val_accuracy: 0.9631\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0237 - accuracy: 0.9980 - val_loss: 0.1721 - val_accuracy: 0.9631\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.0213 - accuracy: 0.9985 - val_loss: 0.1721 - val_accuracy: 0.9631\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0198 - accuracy: 0.9995 - val_loss: 0.1722 - val_accuracy: 0.9631\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0183 - accuracy: 0.9995 - val_loss: 0.1722 - val_accuracy: 0.9631\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0220 - accuracy: 0.9974 - val_loss: 0.1722 - val_accuracy: 0.9631\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9631\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 494ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9631\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.0196 - accuracy: 0.9985 - val_loss: 0.1724 - val_accuracy: 0.9631\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.0190 - accuracy: 0.9990 - val_loss: 0.1723 - val_accuracy: 0.9631\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0189 - accuracy: 0.9995 - val_loss: 0.1723 - val_accuracy: 0.9631\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 495ms/step - loss: 0.0191 - accuracy: 0.9985 - val_loss: 0.1723 - val_accuracy: 0.9631\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0200 - accuracy: 0.9995 - val_loss: 0.1723 - val_accuracy: 0.9631\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0236 - accuracy: 0.9959 - val_loss: 0.1724 - val_accuracy: 0.9631\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0203 - accuracy: 0.9995 - val_loss: 0.1723 - val_accuracy: 0.9631\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0182 - accuracy: 0.9985 - val_loss: 0.1724 - val_accuracy: 0.9631\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0217 - accuracy: 0.9995 - val_loss: 0.1723 - val_accuracy: 0.9631\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0238 - accuracy: 0.9980 - val_loss: 0.1723 - val_accuracy: 0.9631\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.0169 - accuracy: 0.9990 - val_loss: 0.1722 - val_accuracy: 0.9631\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 495ms/step - loss: 0.0190 - accuracy: 0.9995 - val_loss: 0.1722 - val_accuracy: 0.9631\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.0170 - accuracy: 0.9990 - val_loss: 0.1721 - val_accuracy: 0.9631\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0179 - accuracy: 0.9995 - val_loss: 0.1720 - val_accuracy: 0.9631\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0186 - accuracy: 0.9995 - val_loss: 0.1719 - val_accuracy: 0.9631\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.0232 - accuracy: 0.9969 - val_loss: 0.1718 - val_accuracy: 0.9631\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0197 - accuracy: 0.9980 - val_loss: 0.1716 - val_accuracy: 0.9631\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 493ms/step - loss: 0.0213 - accuracy: 0.9980 - val_loss: 0.1714 - val_accuracy: 0.9631\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0191 - accuracy: 0.9995 - val_loss: 0.1712 - val_accuracy: 0.9631\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0188 - accuracy: 0.9990 - val_loss: 0.1712 - val_accuracy: 0.9631\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0201 - accuracy: 0.9995 - val_loss: 0.1710 - val_accuracy: 0.9631\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0208 - accuracy: 0.9995 - val_loss: 0.1709 - val_accuracy: 0.9631\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0237 - accuracy: 0.9980 - val_loss: 0.1708 - val_accuracy: 0.9631\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0223 - accuracy: 0.9974 - val_loss: 0.1706 - val_accuracy: 0.9631\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0192 - accuracy: 0.9995 - val_loss: 0.1705 - val_accuracy: 0.9631\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.0219 - accuracy: 0.9980 - val_loss: 0.1704 - val_accuracy: 0.9631\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0204 - accuracy: 0.9990 - val_loss: 0.1703 - val_accuracy: 0.9631\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0185 - accuracy: 0.9995 - val_loss: 0.1702 - val_accuracy: 0.9631\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.0180 - accuracy: 0.9995 - val_loss: 0.1702 - val_accuracy: 0.9631\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9631\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0203 - accuracy: 0.9995 - val_loss: 0.1700 - val_accuracy: 0.9631\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0200 - accuracy: 0.9980 - val_loss: 0.1700 - val_accuracy: 0.9631\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0218 - accuracy: 0.9985 - val_loss: 0.1699 - val_accuracy: 0.9631\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0221 - accuracy: 0.9985 - val_loss: 0.1698 - val_accuracy: 0.9631\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0196 - accuracy: 0.9995 - val_loss: 0.1698 - val_accuracy: 0.9631\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0246 - accuracy: 0.9985 - val_loss: 0.1697 - val_accuracy: 0.9631\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 1s 510ms/step - loss: 0.0183 - accuracy: 0.9995 - val_loss: 0.1697 - val_accuracy: 0.9631\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9631\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0172 - accuracy: 0.9995 - val_loss: 0.1697 - val_accuracy: 0.9643\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0215 - accuracy: 0.9995 - val_loss: 0.1697 - val_accuracy: 0.9643\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0183 - accuracy: 0.9990 - val_loss: 0.1697 - val_accuracy: 0.9643\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0199 - accuracy: 0.9990 - val_loss: 0.1698 - val_accuracy: 0.9643\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.0223 - accuracy: 0.9980 - val_loss: 0.1698 - val_accuracy: 0.9643\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0202 - accuracy: 0.9990 - val_loss: 0.1698 - val_accuracy: 0.9643\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 498ms/step - loss: 0.0185 - accuracy: 0.9995 - val_loss: 0.1699 - val_accuracy: 0.9631\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0201 - accuracy: 0.9990 - val_loss: 0.1700 - val_accuracy: 0.9631\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0211 - accuracy: 0.9990 - val_loss: 0.1700 - val_accuracy: 0.9631\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0217 - accuracy: 0.9990 - val_loss: 0.1700 - val_accuracy: 0.9631\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.0190 - accuracy: 0.9985 - val_loss: 0.1700 - val_accuracy: 0.9631\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0200 - accuracy: 0.9995 - val_loss: 0.1701 - val_accuracy: 0.9631\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0190 - accuracy: 0.9985 - val_loss: 0.1701 - val_accuracy: 0.9631\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9631\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.0212 - accuracy: 0.9980 - val_loss: 0.1701 - val_accuracy: 0.9631\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0194 - accuracy: 0.9990 - val_loss: 0.1701 - val_accuracy: 0.9631\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0170 - accuracy: 0.9995 - val_loss: 0.1701 - val_accuracy: 0.9643\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9643\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0217 - accuracy: 0.9985 - val_loss: 0.1701 - val_accuracy: 0.9643\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0239 - accuracy: 0.9980 - val_loss: 0.1701 - val_accuracy: 0.9643\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0193 - accuracy: 0.9990 - val_loss: 0.1700 - val_accuracy: 0.9643\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.9643\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.0205 - accuracy: 0.9990 - val_loss: 0.1700 - val_accuracy: 0.9643\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0242 - accuracy: 0.9980 - val_loss: 0.1700 - val_accuracy: 0.9643\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0222 - accuracy: 0.9990 - val_loss: 0.1699 - val_accuracy: 0.9643\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0204 - accuracy: 0.9980 - val_loss: 0.1698 - val_accuracy: 0.9643\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.0194 - accuracy: 0.9995 - val_loss: 0.1698 - val_accuracy: 0.9643\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9643\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0185 - accuracy: 0.9990 - val_loss: 0.1697 - val_accuracy: 0.9643\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.0208 - accuracy: 0.9995 - val_loss: 0.1696 - val_accuracy: 0.9643\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0203 - accuracy: 0.9995 - val_loss: 0.1695 - val_accuracy: 0.9643\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0207 - accuracy: 0.9990 - val_loss: 0.1695 - val_accuracy: 0.9643\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0227 - accuracy: 0.9980 - val_loss: 0.1694 - val_accuracy: 0.9643\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0185 - accuracy: 0.9990 - val_loss: 0.1694 - val_accuracy: 0.9643\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0206 - accuracy: 0.9990 - val_loss: 0.1694 - val_accuracy: 0.9643\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0201 - accuracy: 0.9995 - val_loss: 0.1694 - val_accuracy: 0.9643\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0188 - accuracy: 0.9995 - val_loss: 0.1693 - val_accuracy: 0.9643\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.0190 - accuracy: 0.9980 - val_loss: 0.1693 - val_accuracy: 0.9643\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 498ms/step - loss: 0.0191 - accuracy: 0.9990 - val_loss: 0.1692 - val_accuracy: 0.9643\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.0218 - accuracy: 0.9985 - val_loss: 0.1692 - val_accuracy: 0.9643\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.0205 - accuracy: 0.9995 - val_loss: 0.1692 - val_accuracy: 0.9643\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0194 - accuracy: 0.9990 - val_loss: 0.1692 - val_accuracy: 0.9643\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.0194 - accuracy: 0.9995 - val_loss: 0.1693 - val_accuracy: 0.9643\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.0236 - accuracy: 0.9980 - val_loss: 0.1694 - val_accuracy: 0.9643\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.0219 - accuracy: 0.9985 - val_loss: 0.1694 - val_accuracy: 0.9643\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.1695 - val_accuracy: 0.9643\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0179 - accuracy: 0.9995 - val_loss: 0.1696 - val_accuracy: 0.9643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqh2oDD4ixIS"
      },
      "source": [
        "6.Plotting results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tx0Txay0v5-",
        "outputId": "7ae9ac53-a6fc-44ed-d577-de222bacffe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_K4G9CuTA4d",
        "outputId": "87d3f888-62b0-42d9-9053-5c63e18a447d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        }
      },
      "source": [
        "Y_pred = DD_Net.predict([X_test_0,X_test_1])\n",
        "labels = ['Grab', 'Tap', 'Expand', 'Pinch', 'RC', 'RCC', 'SR', 'SL', 'SU', 'SD', 'SX', 'S+', 'SV', 'Shake']\n",
        "\n",
        "y_true = []\n",
        "for i in np.argmax(Y_test,axis=1):\n",
        "    y_true.append(labels[i])\n",
        "    \n",
        "y_pred = []\n",
        "for i in np.argmax(Y_pred,axis=1):\n",
        "    y_pred.append(labels[i])\n",
        "\n",
        "cm_analysis(y_true,y_pred, 'SHREC_14.png', labels, ymap=None, figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe0Zw66yW47F"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}